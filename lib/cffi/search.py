"""
ê²€ìƒ‰ ëª¨ë“ˆ - curl-cffi

Coupang ìƒí’ˆ ê²€ìƒ‰ ë° ìˆœìœ„ í™•ì¸
"""

import random
from urllib.parse import quote
from concurrent.futures import ThreadPoolExecutor, as_completed

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from cffi.request import make_request, parse_response_cookies, generate_trace_id, timestamp
from extractor.search_extractor import ProductExtractor


def fetch_page(page_num, query, trace_id, cookies, fingerprint, proxy, save_html=False):
    """ë‹¨ì¼ í˜ì´ì§€ ê²€ìƒ‰

    Args:
        page_num: í˜ì´ì§€ ë²ˆí˜¸
        query: ê²€ìƒ‰ì–´
        trace_id: ì¿ íŒ¡ traceId
        cookies: ì¿ í‚¤ ë”•ì…”ë„ˆë¦¬
        fingerprint: í•‘ê±°í”„ë¦°íŠ¸ ë ˆì½”ë“œ
        proxy: í”„ë¡ì‹œ URL
        save_html: HTML ì›ë³¸ ì €ì¥ ì—¬ë¶€

    Returns:
        dict: {page, success, products, size, error, response_cookies, response_cookies_full, html}
    """
    url = f'https://www.coupang.com/np/search?q={quote(query)}&traceId={trace_id}&channel=user&listSize=72&page={page_num}'

    try:
        resp = make_request(url, cookies, fingerprint, proxy)
        size = len(resp.content)

        response_cookies, response_cookies_full = parse_response_cookies(resp)

        if resp.status_code == 200 and size > 5000:
            html_text = resp.text
            result = ProductExtractor.extract_products_from_html(html_text)

            # "ê²€ìƒ‰ê²°ê³¼ ì—†ìŒ" í˜ì´ì§€ ê°ì§€ (ì¿ íŒ¡ ì •ìƒ ì‘ë‹µì´ì§€ë§Œ ìƒí’ˆ ì—†ìŒ)
            is_no_results_page = (
                'ì— ëŒ€í•œ ê²€ìƒ‰ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤' in html_text or
                'ê²€ìƒ‰ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤' in html_text
            )

            return {
                'page': page_num,
                'success': True,
                'products': result['ranking'],
                'size': size,
                'response_cookies': response_cookies,
                'response_cookies_full': response_cookies_full,
                'html': html_text if save_html else None,
                'is_no_results_page': is_no_results_page
            }
        elif resp.status_code == 403:
            return {
                'page': page_num,
                'success': False,
                'products': [],
                'error': 'BLOCKED_403',
                'response_cookies': response_cookies,
                'response_cookies_full': response_cookies_full,
                'html': None
            }
        elif size <= 5000:
            return {
                'page': page_num,
                'success': False,
                'products': [],
                'error': f'CHALLENGE_{size}B',
                'response_cookies': response_cookies,
                'response_cookies_full': response_cookies_full,
                'html': None
            }
        else:
            return {
                'page': page_num,
                'success': False,
                'products': [],
                'error': f'STATUS_{resp.status_code}',
                'response_cookies': response_cookies,
                'response_cookies_full': response_cookies_full,
                'html': None
            }

    except Exception as e:
        return {
            'page': page_num,
            'success': False,
            'products': [],
            'error': str(e)[:150],
            'response_cookies': {},
            'response_cookies_full': [],
            'html': None
        }


def search_product(query, target_product_id, cookies, fingerprint, proxy,
                   max_page=13, verbose=True, save_html=False):
    """ìƒí’ˆ ê²€ìƒ‰ (ì ì§„ì  ë°°ì¹˜)

    ë°°ì¹˜ ì „ëµ:
    - Tier 1: 1í˜ì´ì§€ë§Œ (ëŒ€ë¶€ë¶„ ì—¬ê¸°ì„œ ë°œê²¬)
    - Tier 2: 2-3í˜ì´ì§€ (ë¯¸ë°œê²¬ ì‹œ)
    - Tier 3: 4-13í˜ì´ì§€ (ë¯¸ë°œê²¬ ì‹œ)

    Args:
        query: ê²€ìƒ‰ì–´
        target_product_id: íƒ€ê²Ÿ ìƒí’ˆ ID
        cookies: ì¿ í‚¤ ë”•ì…”ë„ˆë¦¬
        fingerprint: í•‘ê±°í”„ë¦°íŠ¸ ë ˆì½”ë“œ
        proxy: í”„ë¡ì‹œ URL
        max_page: ìµœëŒ€ í˜ì´ì§€
        verbose: ìƒì„¸ ì¶œë ¥
        save_html: HTML ì €ì¥ ì—¬ë¶€ (ìŠ¤í¬ë¦°ìƒ·ìš©)

    Returns:
        dict: {
            found: ë°œê²¬ ìƒí’ˆ ì •ë³´ ë˜ëŠ” None,
            all_products: ëª¨ë“  ìƒí’ˆ ë¦¬ìŠ¤íŠ¸,
            blocked: ì°¨ë‹¨ ì—¬ë¶€,
            block_error: ì°¨ë‹¨ ì—ëŸ¬ ë©”ì‹œì§€,
            total_bytes: ì´ íŠ¸ë˜í”½,
            response_cookies: ì‘ë‹µ ì¿ í‚¤,
            response_cookies_full: ì‘ë‹µ ì¿ í‚¤ (ì „ì²´ ì†ì„±),
            found_html: ìƒí’ˆ ë°œê²¬ í˜ì´ì§€ HTML (save_html=Trueì¸ ê²½ìš°)
        }
    """
    trace_id = generate_trace_id()
    if verbose:
        print(f"\n[{timestamp()}] ê²€ìƒ‰ ì¤‘... (traceId: {trace_id})")

    found = None
    found_html = None  # ìƒí’ˆ ë°œê²¬ í˜ì´ì§€ HTML
    all_products = []
    blocked = False
    block_error = ''
    page_errors = []  # ê° í˜ì´ì§€ë³„ ì—ëŸ¬ ìˆ˜ì§‘
    total_bytes = 0
    all_response_cookies = {}
    all_response_cookies_full = []

    # ë°°ì¹˜ ì •ì˜ (ë¹ˆ ë°°ì¹˜ ì œì™¸)
    batches = [
        [1],                    # Tier 1
        [2, 3],                 # Tier 2
        list(range(4, min(max_page + 1, 14)))  # Tier 3
    ]
    batches = [b for b in batches if b]  # ë¹ˆ ë°°ì¹˜ ì œê±°

    cookies_ref = cookies.copy()  # ì¿ í‚¤ ì—…ë°ì´íŠ¸ìš©

    # ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ í”Œë˜ê·¸ (1í˜ì´ì§€ 0ê°œë©´ ì¡°ê¸° ì¢…ë£Œ)
    no_results = False

    for batch_idx, pages in enumerate(batches):
        if found or blocked or no_results:
            break

        if verbose:
            tier_name = ['1í˜ì´ì§€', '2-3í˜ì´ì§€', f'4-{max_page}í˜ì´ì§€'][batch_idx]
            print(f"  Tier {batch_idx + 1}: {tier_name}")

        with ThreadPoolExecutor(max_workers=len(pages)) as executor:
            futures = {
                executor.submit(
                    fetch_page, p, query, trace_id, cookies_ref, fingerprint, proxy, save_html
                ): p for p in pages
            }

            for future in as_completed(futures):
                result = future.result()

                # ì‘ë‹µ ì¿ í‚¤ ìˆ˜ì§‘ (í•„ìˆ˜)
                all_response_cookies.update(result['response_cookies'])
                cookies_ref.update(result['response_cookies'])  # ë‹¤ìŒ ìš”ì²­ì— ë°˜ì˜
                all_response_cookies_full.extend(result['response_cookies_full'])

                total_bytes += result.get('size', 0)

                if result['success']:
                    for product in result['products']:
                        product['_page'] = result['page']
                        all_products.append(product)

                        if product['productId'] == target_product_id and not found:
                            found = product
                            found['page'] = result['page']
                            # ìŠ¤í¬ë¦°ìƒ·ìš© HTML ì €ì¥
                            if save_html and result.get('html'):
                                found_html = result['html']
                            if verbose:
                                print(f"  [{timestamp()}] âœ… ë°œê²¬! Page {result['page']}, Rank {product['rank']}")

                    if verbose and not found:
                        print(f"    Page {result['page']:2d}: {len(result['products'])}ê°œ")
                else:
                    error = result.get('error', '')
                    if error:
                        page_errors.append({'page': result['page'], 'error': error})
                    if verbose:
                        print(f"    Page {result['page']:2d}: âŒ {error}")

                    # HTTP/2 ìŠ¤íŠ¸ë¦¼ ì—ëŸ¬ë„ ì°¨ë‹¨ìœ¼ë¡œ ì²˜ë¦¬ (ê°€ì¥ í”í•œ ì°¨ë‹¨ ë°©ì‹)
                    if (error == 'BLOCKED_403' or
                        error.startswith('CHALLENGE_') or
                        'HTTP/2 stream' in error or
                        'curl: (92)' in error):
                        blocked = True
                        if 'HTTP/2 stream' in error or 'curl: (92)' in error:
                            block_error = 'HTTP2_PROTOCOL_ERROR'
                        else:
                            block_error = error
                        for f in futures:
                            f.cancel()
                        break

                    # 1í˜ì´ì§€ íƒ€ì„ì•„ì›ƒ ì‹œ ì¡°ê¸° ì¢…ë£Œ (í”„ë¡ì‹œ ë¬¸ì œ)
                    if (batch_idx == 0 and result['page'] == 1 and
                        ('timed out' in error.lower() or 'curl: (28)' in error or
                         'Could not connect' in error or 'curl: (7)' in error)):
                        blocked = True
                        block_error = 'PROXY_TIMEOUT'
                        if verbose:
                            print(f"  ğŸ›‘ 1í˜ì´ì§€ íƒ€ì„ì•„ì›ƒ â†’ ì¡°ê¸° ì¢…ë£Œ")
                        for f in futures:
                            f.cancel()
                        break

        # Tier 1 ì™„ë£Œ í›„ ê²€ìƒ‰ ê²°ê³¼ê°€ 0ê°œë©´ ì¡°ê¸° ì¢…ë£Œ
        # no_resultsëŠ” ì¿ íŒ¡ì´ ëª…ì‹œì ìœ¼ë¡œ "ê²€ìƒ‰ê²°ê³¼ ì—†ìŒ"ì„ ë°˜í™˜í•œ ê²½ìš°ì—ë§Œ True
        # ì—ëŸ¬(íƒ€ì„ì•„ì›ƒ ë“±)ë¡œ ì¸í•œ 0ê°œëŠ” no_results = False
        if batch_idx == 0 and len(all_products) == 0 and not blocked:
            # ì—ëŸ¬ ì—†ì´ ì„±ê³µí•œ ìš”ì²­ ì¤‘ "ê²€ìƒ‰ê²°ê³¼ ì—†ìŒ" í˜ì´ì§€ê°€ ìˆëŠ”ì§€ í™•ì¸
            is_coupang_no_results = any(
                f.result().get('is_no_results_page', False)
                for f in futures if f.done() and not f.cancelled() and f.result().get('success')
            )

            if is_coupang_no_results:
                no_results = True  # ì¿ íŒ¡ì´ ëª…ì‹œì ìœ¼ë¡œ ê²€ìƒ‰ê²°ê³¼ ì—†ìŒ ë°˜í™˜
                if verbose:
                    print(f"  âš ï¸ ì¿ íŒ¡ ê²€ìƒ‰ê²°ê³¼ ì—†ìŒ - ì¡°ê¸° ì¢…ë£Œ")
            else:
                no_results = False  # ì—ëŸ¬ë¡œ ì¸í•œ 0ê°œ (íƒ€ì„ì•„ì›ƒ ë“±)
                if verbose:
                    print(f"  âš ï¸ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ - ì¡°ê¸° ì¢…ë£Œ")

    # ì‹¤ì œ ìˆœìœ„ ê³„ì‚°
    all_products.sort(key=lambda p: (p['_page'], p.get('rank') or 999))
    for i, product in enumerate(all_products):
        product['actual_rank'] = i + 1

    actual_rank = None
    if found:
        for product in all_products:
            if product['productId'] == target_product_id:
                actual_rank = product['actual_rank']
                break

    return {
        'found': found,
        'actual_rank': actual_rank,
        'all_products': all_products,
        'blocked': blocked,
        'block_error': block_error,
        'page_errors': page_errors,
        'total_bytes': total_bytes,
        'trace_id': trace_id,
        'response_cookies': all_response_cookies,
        'response_cookies_full': all_response_cookies_full,
        'found_html': found_html,
        'no_results': no_results  # ì¿ íŒ¡ì´ "ê²€ìƒ‰ê²°ê³¼ ì—†ìŒ" ì‘ë‹µ (ì •ìƒì ì¸ ë¯¸ë°œê²¬)
    }


if __name__ == '__main__':
    print("ê²€ìƒ‰ ëª¨ë“ˆ í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    print("ì‚¬ìš©ë²•: search.pyëŠ” ì§ì ‘ ì‹¤í–‰í•˜ì§€ ì•Šê³  ëª¨ë“ˆë¡œ importí•˜ì—¬ ì‚¬ìš©")

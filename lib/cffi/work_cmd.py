"""
ì‘ì—… í• ë‹¹ API ê¸°ë°˜ ê²€ìƒ‰ ì‹¤í–‰

API:
  - í• ë‹¹: GET  http://mkt.techb.kr:29998/api/work/allocate/rank
  - ê²°ê³¼: POST http://mkt.techb.kr:29998/api/work/result/rank

ê²°ê³¼ ë³´ê³  ì‹œë‚˜ë¦¬ì˜¤:
  1. ìˆœìœ„ ë°œê²¬: status='success', rank=N
  2. ìˆœìœ„ ë¯¸ë°œê²¬: status='success', rank=0
  3. ìˆœìœ„ì²´í¬ ì˜¤ë¥˜ (ìƒí’ˆì •ë³´ë§Œ): status='success', rank=None, info={...}
  4. í”„ë¡ì‹œ ì˜¤ë¥˜: status='failed'
"""

import json
import signal
import threading
import unicodedata
from datetime import datetime
from pathlib import Path
from urllib.parse import quote
from concurrent.futures import ThreadPoolExecutor, as_completed

import sys
sys.path.insert(0, str(Path(__file__).parent.parent))

from common.proxy import get_bound_cookie, get_subnet, update_cookie_stats, update_cookie_data
from common.fingerprint import get_random_fingerprint
from cffi.search import search_product
from cffi.click import click_product, extract_ids_from_url
from extractor.filter_extractor import DEFAULT_FILTER_CATEGORIES, find_searchable_category
from cffi.request import timestamp, make_request, parse_response_cookies
from cffi.work_api import allocate_work, report_result, build_info_data
from extractor.detail_extractor import extract_product_detail, to_api_response
from screenshot import save_html_with_urls, take_screenshot_from_saved

# í”„ë¡œì íŠ¸ ë£¨íŠ¸
PROJECT_ROOT = Path(__file__).parent.parent.parent


def direct_access_product(product_id, item_id, vendor_item_id, cookies, fingerprint, proxy, save_html=False, verbose=True):
    """ìƒí’ˆ URL ì§ì ‘ ì ‘ì†"""
    if item_id and vendor_item_id:
        url = f'https://www.coupang.com/vp/products/{product_id}?itemId={item_id}&vendorItemId={vendor_item_id}'
    else:
        url = f'https://www.coupang.com/vp/products/{product_id}'

    if verbose:
        print(f"\n[{timestamp()}] ì§ì ‘ ì ‘ì†...")
        print(f"  URL: {url}")

    try:
        resp = make_request(url, cookies, fingerprint, proxy, referer='https://www.coupang.com/')
        size = len(resp.content)
        response_cookies, response_cookies_full = parse_response_cookies(resp)
        html_content = resp.text

        if verbose:
            print(f"  Status: {resp.status_code} | Size: {size:,} bytes")

        # HTML ì €ì¥ (ì‚¬ì´ì¦ˆì™€ ê´€ê³„ì—†ì´ í•­ìƒ ì €ì¥)
        if save_html:
            html_dir = PROJECT_ROOT / 'html'
            html_dir.mkdir(parents=True, exist_ok=True)
            html_path = html_dir / f'{product_id}.html'
            html_path.write_text(html_content, encoding='utf-8')
            if verbose:
                print(f"  ğŸ“„ HTML ì €ì¥: {html_path}")

        if size > 100000:
            product_data = extract_product_detail(html_content)
            return {
                'success': True,
                'productData': product_data,
                'response_cookies_full': response_cookies_full,
                'size': size,
                'html': html_content
            }
        else:
            return {
                'success': False,
                'error': f'INVALID_RESPONSE_{size}B',
                'response_cookies_full': response_cookies_full,
                'size': size,
                'html': html_content
            }
    except Exception as e:
        return {
            'success': False,
            'error': str(e)[:100],
            'response_cookies_full': [],
            'size': 0
        }


def run_work(args):
    """ì‘ì—… ì‹¤í–‰"""
    work_type = getattr(args, 'type', 'rank')

    print("=" * 70)
    print(f"ì‘ì—… í• ë‹¹ ê²€ìƒ‰ [{work_type}]")
    print("=" * 70)

    # 1. ì‘ì—… í• ë‹¹ ë°›ê¸°
    work_id = getattr(args, 'id', None)
    if work_id:
        print(f"\nğŸ“¥ ì‘ì—… ì¡°íšŒ (ID: {work_id}, type: {work_type})...")
    else:
        print(f"\nğŸ“¥ ì‘ì—… í• ë‹¹ ìš”ì²­ (type: {work_type})...")

    allocation = allocate_work(work_id=work_id, work_type=work_type)
    if not allocation:
        print("âŒ ì‘ì—… ì—†ìŒ" if not work_id else f"âŒ ID {work_id} ì‘ì—… ì—†ìŒ")
        return None

    # í• ë‹¹ ì‘ë‹µ JSON ì¶œë ¥
    print(f"{'â”€' * 60}")
    print(json.dumps(allocation, ensure_ascii=False, indent=2))
    print(f"{'â”€' * 60}")

    progress_id = allocation['progress_id']
    keyword = allocation['keyword']
    product_id = str(allocation['product_id'])
    item_id = allocation.get('item_id')
    vendor_item_id = allocation.get('vendor_item_id')
    allocated_proxy = allocation.get('proxy')
    external_ip = allocation.get('external_ip')
    need_screenshot = allocation.get('shot_data', False)

    # 2. í• ë‹¹ëœ í”„ë¡ì‹œì˜ ì„œë¸Œë„·ì— ë§ëŠ” ì¿ í‚¤ ì°¾ê¸°
    if external_ip:
        target_subnet = get_subnet(external_ip)
        print(f"\nğŸ” ì¿ í‚¤ íƒìƒ‰ (ì„œë¸Œë„·: {target_subnet}.*)")

        bound = get_bound_cookie(min_remain=30, max_age_minutes=60, target_subnet=target_subnet)
        if not bound:
            # ì„œë¸Œë„· ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì¼ë°˜ ì¿ í‚¤ ì‚¬ìš©
            print(f"  âš ï¸ ì„œë¸Œë„· ë§¤ì¹­ ì¿ í‚¤ ì—†ìŒ - ì¼ë°˜ ì¿ í‚¤ ì‚¬ìš©")
            bound = get_bound_cookie(min_remain=30, max_age_minutes=60)

        if not bound:
            print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì¿ í‚¤ ì—†ìŒ")
            report_result(progress_id, allocated_proxy, external_ip, 'failed', work_type=work_type)
            return None

        cookie_record = bound['cookie_record']
        cookies = bound['cookies']

        # í• ë‹¹ëœ í”„ë¡ì‹œ ì‚¬ìš© (APIì—ì„œ ì§€ì •)
        proxy = f"socks5://{allocated_proxy}"

        match_type = 'exact' if get_subnet(cookie_record['proxy_ip']) == target_subnet else 'fallback'
        print(f"  âœ… ì¿ í‚¤ ID: {cookie_record['id']} ({match_type})")
        print(f"     ì¿ í‚¤ IP: {cookie_record['proxy_ip']}")
    else:
        # external_ip ì—†ìœ¼ë©´ ìë™ ë°”ì¸ë”©
        bound = get_bound_cookie(min_remain=30, max_age_minutes=60)
        if not bound:
            print("âŒ IP ë°”ì¸ë”© ë§¤ì¹­ ì‹¤íŒ¨")
            report_result(progress_id, allocated_proxy or '', external_ip or '', 'failed', work_type=work_type)
            return None

        cookie_record = bound['cookie_record']
        cookies = bound['cookies']
        proxy = bound['proxy']
        print(f"  âœ… ì¿ í‚¤ ID: {cookie_record['id']} (auto)")

    # 3. í•‘ê±°í”„ë¦°íŠ¸
    fingerprint = get_random_fingerprint(verified_only=True)
    if not fingerprint:
        print("âŒ í•‘ê±°í”„ë¦°íŠ¸ ì—†ìŒ")
        report_result(progress_id, allocated_proxy or '', external_ip or '', 'failed', work_type=work_type)
        return None

    print(f"\níƒ€ê²Ÿ: {product_id}")
    print(f"ê²€ìƒ‰ì–´: {keyword}")
    print(f"TLS: Chrome {fingerprint['chrome_major']}")
    print(f"í”„ë¡ì‹œ: {proxy}")
    print("=" * 70)

    # 4. ê²€ìƒ‰ ì‹¤í–‰
    start_time = datetime.now()
    max_page = args.max_page if hasattr(args, 'max_page') else 13

    result = search_product(
        keyword,
        product_id,
        cookies,
        fingerprint,
        proxy,
        max_page=max_page,
        verbose=True,
        save_html=need_screenshot
    )

    search_time = (datetime.now() - start_time).total_seconds()

    # 5. ê²°ê³¼ ì²˜ë¦¬
    print("\n" + "=" * 70)
    print("ê²°ê³¼")
    print("=" * 70)

    found = result['found']
    blocked = result['blocked']

    # ê²°ê³¼ ë³´ê³  ë³€ìˆ˜
    report_rank = None
    report_info = None

    if found:
        print(f"\nâœ… ìƒí’ˆ ë°œê²¬")
        print(f"   í˜ì´ì§€: {found['page']}")
        print(f"   ìˆœìœ„: {result['actual_rank']}ë“± / {len(result['all_products'])}ê°œ")

        report_rank = result['actual_rank']

        # ìŠ¤í¬ë¦°ìƒ· ì²˜ë¦¬
        if need_screenshot and result.get('found_html'):
            ts = datetime.now().strftime('%Y%m%d_%H%M%S')
            screenshot_dir = PROJECT_ROOT / 'screenshot'
            screenshot_dir.mkdir(parents=True, exist_ok=True)
            html_path = screenshot_dir / f'work_{progress_id}_{ts}.html'

            save_result = save_html_with_urls(
                result['found_html'],
                html_path,
                metadata={
                    'progress_id': progress_id,
                    'keyword': keyword,
                    'product_id': product_id,
                    'rank': result['actual_rank'],
                    'page': found['page'],
                    'timestamp': ts
                }
            )
            print(f"\nğŸ“„ HTML ì €ì¥: {save_result['html_path']}")

            print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ìƒì„± ì¤‘...")
            ss_result = take_screenshot_from_saved(html_path)
            if ss_result['success']:
                print(f"   âœ… {ss_result['path']}")

        # í´ë¦­
        if not getattr(args, 'no_click', False):
            print(f"\n[{timestamp()}] ìƒí’ˆ í´ë¦­...")

            ids = extract_ids_from_url(found['url'])
            product_info = {
                'productId': found['productId'],
                'url': found['url'],
                'rank': found['rank'],
                'itemId': ids['itemId'],
                'vendorItemId': ids['vendorItemId']
            }

            search_url = f'https://www.coupang.com/np/search?q={quote(keyword)}'
            click_result = click_product(
                product_info, search_url, cookies, fingerprint, proxy,
                save_html=True  # HTML ì €ì¥
            )

            if click_result['success']:
                # í´ë¦­ ì„±ê³µ ì‹œ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ
                if click_result.get('productData'):
                    report_info = build_info_data(to_api_response(click_result['productData']))
            else:
                print(f"  âŒ í´ë¦­ ì‹¤íŒ¨: {click_result.get('error')}")

    elif blocked:
        # í”„ë¡ì‹œ ì°¨ë‹¨ = failed
        print(f"\nğŸš« ì°¨ë‹¨ë¨: {result['block_error']}")

    else:
        # ë¯¸ë°œê²¬ vs ê²€ìƒ‰ì˜¤ë¥˜ êµ¬ë¶„
        search_count = len(result['all_products'])
        page_errors = result.get('page_errors', [])
        no_results = result.get('no_results', False)  # ì¿ íŒ¡ "ê²€ìƒ‰ê²°ê³¼ ì—†ìŒ" ì‘ë‹µ

        if no_results:
            # ì¿ íŒ¡ì´ "ê²€ìƒ‰ê²°ê³¼ ì—†ìŒ" ì‘ë‹µ = ì •ìƒì ì¸ ë¯¸ë°œê²¬
            print(f"\nâŒ ìƒí’ˆ ë¯¸ë°œê²¬ (ì¿ íŒ¡ ê²€ìƒ‰ê²°ê³¼ ì—†ìŒ)")
            report_rank = 0
        elif search_count == 0 and page_errors:
            # ê²€ìƒ‰ëœ ìƒí’ˆ 0ê°œ + ì—ëŸ¬ ìˆìŒ = í”„ë¡ì‹œ ì˜¤ë¥˜ (ì§ì ‘ ì ‘ì† ì‹œë„ ì•ˆí•¨)
            print(f"\nâš ï¸ ê²€ìƒ‰ ì˜¤ë¥˜ â†’ í”„ë¡ì‹œ ì‹¤íŒ¨ ì²˜ë¦¬ (ì—ëŸ¬: {len(page_errors)}ê±´)")
            for err in page_errors[:3]:  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
                print(f"   - P{err['page']}: {err['error'][:50]}")
            blocked = True  # ë°”ë¡œ failed ì²˜ë¦¬
        else:
            # ê²€ìƒ‰í–ˆì§€ë§Œ íƒ€ê²Ÿ ìƒí’ˆ ì—†ìŒ = rank 0
            print(f"\nâŒ ìƒí’ˆ ë¯¸ë°œê²¬ ({search_count}ê°œ ê²€ìƒ‰)")
            report_rank = 0

        # ì§ì ‘ ì ‘ì†ìœ¼ë¡œ ìƒí’ˆ ì •ë³´ ìˆ˜ì§‘ (ê²€ìƒ‰ ì˜¤ë¥˜ê°€ ì•„ë‹ ë•Œë§Œ)
        if not blocked and not getattr(args, 'no_click', False):
            direct_result = direct_access_product(
                product_id, item_id, vendor_item_id,
                cookies, fingerprint, proxy,
                save_html=True  # HTML ì €ì¥
            )

            if direct_result['success']:
                product_data = direct_result.get('productData', {})
                if product_data:
                    print(f"\nğŸ“¦ ì§ì ‘ ì ‘ì† ì„±ê³µ")
                    api_data = to_api_response(product_data)
                    report_info = build_info_data(api_data)

            if direct_result.get('response_cookies_full'):
                result['response_cookies_full'].extend(direct_result['response_cookies_full'])

    # 6. ì¿ í‚¤ í†µê³„ ì—…ë°ì´íŠ¸
    is_success = not blocked
    update_cookie_stats(cookie_record['id'], is_success)

    updated = update_cookie_data(cookie_record['id'], result.get('response_cookies_full', []))
    if updated > 0:
        print(f"\nğŸ’¾ ì¿ í‚¤ ì—…ë°ì´íŠ¸: {updated}ê°œ")

    # ì¹´í…Œê³ ë¦¬ í•„í„° ì§€ì› ì—¬ë¶€ ë¡œê·¸
    if report_info and report_info.get('categories'):
        cats = report_info['categories']
        searchable = find_searchable_category(cats, DEFAULT_FILTER_CATEGORIES)
        if searchable:
            print(f"\nğŸ·ï¸ ì¹´í…Œê³ ë¦¬: {searchable['name']} ({searchable['id']}) - ê²€ìƒ‰í•„í„° ì§€ì› âœ…")
        else:
            cat_names = ' > '.join([c['name'] for c in cats[:3]])
            print(f"\nğŸ·ï¸ ì¹´í…Œê³ ë¦¬: {cat_names} - ê²€ìƒ‰í•„í„° ë¯¸ì§€ì› âŒ")

    # 7. ê²°ê³¼ ë³´ê³  (work_api ëª¨ë“ˆ ì‚¬ìš©)
    print(f"\nğŸ“¤ ê²°ê³¼ ë³´ê³ ...")

    # status ê²°ì •: blockedë©´ failed, ì•„ë‹ˆë©´ success
    report_status = 'failed' if blocked else 'success'

    # ë³´ê³ í•  payload êµ¬ì„±
    report_payload = {
        'progress_id': progress_id,
        'proxy': allocated_proxy or '',
        'external_ip': external_ip or '',
        'status': report_status
    }
    if report_rank is not None:
        report_payload['rank'] = report_rank
    if report_info:
        report_payload['info'] = report_info

    # ìš”ì²­ payload ì¶œë ¥
    print(f"{'â”€' * 60}")
    print(json.dumps(report_payload, ensure_ascii=False, indent=2))
    print(f"{'â”€' * 60}")

    report_resp = report_result(
        progress_id=progress_id,
        proxy=allocated_proxy or '',
        external_ip=external_ip or '',
        status=report_status,
        rank=report_rank,
        info=report_info,
        work_type=work_type
    )

    if report_resp:
        print(f"   âœ… ì‘ë‹µ:")
        print(f"{'â”€' * 60}")
        print(json.dumps(report_resp, ensure_ascii=False, indent=2))
        print(f"{'â”€' * 60}")
    else:
        print(f"   âš ï¸ ë³´ê³  ì‹¤íŒ¨")

    # íŠ¸ë˜í”½
    total_bytes = result.get('total_bytes', 0)
    if total_bytes > 0:
        traffic_str = f"{total_bytes / 1024:.2f} KB" if total_bytes < 1024 * 1024 else f"{total_bytes / (1024 * 1024):.2f} MB"
        print(f"\nğŸ“Š íŠ¸ë˜í”½: {traffic_str} | ì‹œê°„: {search_time:.1f}ì´ˆ")

    print(f"\nâœ… Progress:{progress_id} | ì¿ í‚¤:{cookie_record['id']} | TLS:{fingerprint['chrome_major']}")

    return {
        'progress_id': progress_id,
        'found': bool(found),
        'blocked': blocked,
        'rank': result.get('actual_rank'),
        'cookie_id': cookie_record['id']
    }




# ============================================================================
# í•„í„° URL íƒìƒ‰ ëª¨ë“œ
# ============================================================================

def search_with_filter(keyword, target_product_id, min_price, max_price, cookies, fingerprint, proxy, page=1, component=None):
    """í•„í„° ì ìš© ê²€ìƒ‰

    Args:
        keyword: ê²€ìƒ‰ì–´
        target_product_id: ì°¾ì„ ìƒí’ˆ ID
        min_price: ìµœì†Œ ê°€ê²©
        max_price: ìµœëŒ€ ê°€ê²©
        cookies: ì¿ í‚¤ ë”•ì…”ë„ˆë¦¬
        fingerprint: í•‘ê±°í”„ë¦°íŠ¸ ë ˆì½”ë“œ
        proxy: í”„ë¡ì‹œ URL
        page: í˜ì´ì§€ ë²ˆí˜¸
        component: ì¹´í…Œê³ ë¦¬ ID (component íŒŒë¼ë¯¸í„°)

    Returns:
        dict: {found, rank, page, total_products, url, error}
    """
    from extractor.search_extractor import ProductExtractor

    component_str = component if component else ''
    url = (
        f"https://www.coupang.com/np/search?"
        f"listSize=36&filterType=&rating=0&isPriceRange=false"
        f"&minPrice={min_price}&maxPrice={max_price}"
        f"&component={component_str}&sorter=scoreDesc&brand=&offerCondition="
        f"&filter=&fromComponent=N&channel=user"
        f"&selectedPlpKeepFilter=&page={page}"
        f"&q={quote(keyword)}"
    )

    try:
        resp = make_request(url, cookies, fingerprint, proxy)
        size = len(resp.content)

        if resp.status_code == 200 and size > 5000:
            html_text = resp.text
            result = ProductExtractor.extract_products_from_html(html_text)
            products = result['ranking']

            # íƒ€ê²Ÿ ìƒí’ˆ ì°¾ê¸°
            for product in products:
                if product['productId'] == target_product_id:
                    return {
                        'found': True,
                        'rank': product.get('rank'),
                        'page': page,
                        'total_products': len(products),
                        'url': url
                    }

            return {
                'found': False,
                'page': page,
                'total_products': len(products),
                'url': url
            }
        else:
            # ì°¨ë‹¨ ì—¬ë¶€ íŒë‹¨ (200ì´ì§€ë§Œ í¬ê¸°ê°€ ì‘ìœ¼ë©´ Challenge í˜ì´ì§€)
            is_blocked = (resp.status_code == 200 and size < 5000) or resp.status_code == 403
            return {
                'found': False,
                'error': f'STATUS_{resp.status_code}_{size}B',
                'blocked': is_blocked
            }

    except Exception as e:
        return {'found': False, 'error': str(e)[:100]}


def find_filter_url(keyword, product_id, price, cookies, fingerprint, proxy, categories=None, original_price=None, verbose=True):
    """í•„í„° URL íƒìƒ‰

    Args:
        keyword: ê²€ìƒ‰ì–´
        product_id: ìƒí’ˆ ID
        price: í• ì¸ê°€ (ìµœì¢… ê°€ê²©)
        cookies: ì¿ í‚¤ ë”•ì…”ë„ˆë¦¬
        fingerprint: í•‘ê±°í”„ë¦°íŠ¸ ë ˆì½”ë“œ
        proxy: í”„ë¡ì‹œ URL
        categories: ì¹´í…Œê³ ë¦¬ ëª©ë¡ [{'id': '123', 'name': '...'}, ...]
        original_price: ì›ê°€ (ì¿ íŒ¡íŒë§¤ê°€) - í•„í„°ì—ì„œ ìš°ì„  ì‚¬ìš©
        verbose: ìƒì„¸ ì¶œë ¥

    Returns:
        str: ì„±ê³µí•œ í•„í„° URL (ì‹¤íŒ¨ ì‹œ None)
    """
    # ì¹´í…Œê³ ë¦¬ ëª©ë¡ (ëŒ€ë¶„ë¥˜ â†’ ì†Œë¶„ë¥˜ ìˆœì„œë¡œ ì‹œë„)
    # ëŒ€ë¶„ë¥˜ì—ì„œ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ ì†Œë¶„ë¥˜ëŠ” ì‹œë„í•  í•„ìš” ì—†ìŒ
    category_list = []
    if categories and len(categories) > 0:
        category_list = [{'id': c.get('id'), 'name': c.get('name', '?')} for c in categories if c.get('id')]

    # ì‹œë„í•  ê°€ê²© ëª©ë¡ ê²°ì • (ì›ê°€ ìš°ì„ , í• ì¸ê°€ ë‹¤ìŒ)
    prices_to_try = []
    if original_price and original_price != price:
        prices_to_try.append(('ì¿ íŒ¡íŒë§¤ê°€', original_price))
        prices_to_try.append(('í• ì¸ê°€', price))
    else:
        prices_to_try.append(('íŒë§¤ê°€', price))

    if verbose:
        print(f"\n{'=' * 70}")
        print(f"í•„í„° URL íƒìƒ‰")
        print(f"{'=' * 70}")
        print(f"ê²€ìƒ‰ì–´: {keyword}")
        print(f"ìƒí’ˆID: {product_id}")
        if original_price and original_price != price:
            print(f"ì¿ íŒ¡íŒë§¤ê°€: {original_price:,}ì› (ìš°ì„ )")
            print(f"í• ì¸ê°€: {price:,}ì›")
        else:
            print(f"ê¸°ì¤€ê°€ê²©: {price:,}ì›")
        if category_list:
            cat_names = ' > '.join([c['name'] for c in category_list])
            print(f"ì¹´í…Œê³ ë¦¬: {cat_names}")
            print(f"  (ëŒ€ë¶„ë¥˜ë¶€í„° ì‹œë„: {' â†’ '.join([c['id'] for c in category_list])})")
        print(f"{'=' * 70}")

    timeout_count = 0  # íƒ€ì„ì•„ì›ƒ ì—°ì† ì¹´ìš´í„°
    block_count = 0    # ì°¨ë‹¨ ëˆ„ì  ì¹´ìš´í„° (í•œ ë²ˆ ì°¨ë‹¨ë˜ë©´ ì¿ í‚¤ ë¬¸ì œì´ë¯€ë¡œ ëˆ„ì ìœ¼ë¡œ íŒë‹¨)

    # ê° ê°€ê²©(ì›ê°€ ìš°ì„ , í• ì¸ê°€ ë‹¤ìŒ)ì— ëŒ€í•´ ì‹œë„
    for price_idx, (price_name, base_price) in enumerate(prices_to_try):
        if verbose:
            print(f"\n{'â”' * 70}")
            print(f"ğŸ’µ {price_name} ê¸°ì¤€ íƒìƒ‰: {base_price:,}ì›")
            print(f"{'â”' * 70}")

        # ê°€ê²© ë²”ìœ„ ì „ëµë“¤ (í•´ë‹¹ ê°€ê²© ê¸°ì¤€ìœ¼ë¡œ ìƒì„±)
        # í• ì¸ì´ ìˆìœ¼ë©´ ê°€ê²©ì´ ë‚´ë ¤ê°€ëŠ” ê²½ìš°ë§Œ ìˆìŒ â†’ maxPriceëŠ” ê³ ì •, minPriceë§Œ ë‚®ì¶¤
        price_strategies = [
            # 1. ì •í™•í•œ ê°€ê²©
            (base_price, base_price),
            # 2. -5% ~ íŒë§¤ê°€
            (int(base_price * 0.95), base_price),
            # 3. -10% ~ íŒë§¤ê°€
            (int(base_price * 0.90), base_price),
            # 4. -20% ~ íŒë§¤ê°€
            (int(base_price * 0.80), base_price),
            # 5. -30% ~ íŒë§¤ê°€
            (int(base_price * 0.70), base_price),
            # 6. -50% ~ íŒë§¤ê°€
            (int(base_price * 0.50), base_price),
            # 7. í•„í„° ì—†ìŒ
            (0, 0),
        ]

        # Phase 1: ì¹´í…Œê³ ë¦¬ + ê°€ê²© (ëŒ€ë¶„ë¥˜ë¶€í„° ì†Œë¶„ë¥˜ ìˆœì„œë¡œ)
        # ëŒ€ë¶„ë¥˜ì—ì„œ ê²°ê³¼ê°€ ì—†ìœ¼ë©´ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ëŠ” ì‹œë„í•˜ì§€ ì•ŠìŒ
        if category_list:
            if verbose:
                print(f"\nğŸ“‚ Phase 1: ì¹´í…Œê³ ë¦¬ + ê°€ê²© í•„í„° (ëŒ€ë¶„ë¥˜â†’ì†Œë¶„ë¥˜)")

            for cat_idx, cat_info in enumerate(category_list):
                category_id = cat_info['id']
                category_name = cat_info['name']
                category_has_results = False  # ì´ ì¹´í…Œê³ ë¦¬ì—ì„œ ìƒí’ˆì´ ìˆì—ˆëŠ”ì§€

                if verbose:
                    print(f"\n{'â”€' * 50}")
                    print(f"ğŸ“ ì¹´í…Œê³ ë¦¬ [{cat_idx + 1}/{len(category_list)}]: {category_name} ({category_id})")

                for strategy_idx, (min_p, max_p) in enumerate(price_strategies):
                    # ê°€ê²© í•„í„° ì„¤ì •
                    if min_p == 0 and max_p == 0:
                        price_label = "ê°€ê²©í•„í„° ì—†ìŒ"
                        min_price, max_price = 0, 0
                    else:
                        price_label = f"{min_p:,}ì› ~ {max_p:,}ì›"
                        min_price, max_price = min_p, max_p

                    # URL ë¯¸ë¦¬ ìƒì„± (ì¶œë ¥ìš©)
                    preview_url = (
                        f"https://www.coupang.com/np/search?"
                        f"listSize=36&minPrice={min_price}&maxPrice={max_price}"
                        f"&component={category_id}&sorter=scoreDesc&page=1"
                        f"&q={quote(keyword)}"
                    )

                    if verbose:
                        print(f"\n[1-{cat_idx + 1}-{strategy_idx + 1}] {price_label}")
                        print(f"  URL: {preview_url}")

                    # 1~3í˜ì´ì§€ ê²€ìƒ‰
                    for page in range(1, 4):
                        result = search_with_filter(
                            keyword, product_id, min_price, max_price,
                            cookies, fingerprint, proxy, page,
                            component=category_id
                        )

                        if result.get('error'):
                            error = result['error']
                            is_blocked = result.get('blocked', False)

                            if is_blocked:
                                block_count += 1
                                if verbose:
                                    print(f"  Page {page}: ğŸš« ì°¨ë‹¨ ({error[:40]}) [{block_count}/2]")
                                if block_count >= 2:
                                    if verbose:
                                        print(f"  âš ï¸ ì°¨ë‹¨ {block_count}íšŒ â†’ ì¿ í‚¤ ë§Œë£Œë¡œ ì¤‘ë‹¨")
                                    return None
                            elif 'timed out' in error.lower() or 'curl: (28)' in error or 'curl: (7)' in error:
                                timeout_count += 1
                                if verbose:
                                    print(f"  Page {page}: âŒ {error[:60]}")
                                if timeout_count >= 3:
                                    if verbose:
                                        print(f"  âš ï¸ íƒ€ì„ì•„ì›ƒ {timeout_count}íšŒ â†’ í”„ë¡ì‹œ ë¬¸ì œë¡œ ì¤‘ë‹¨")
                                    return None
                            else:
                                if verbose:
                                    print(f"  Page {page}: âŒ {error[:60]}")
                            break
                        elif result['found']:
                            if verbose:
                                print(f"  Page {page}: âœ… ë°œê²¬! Rank #{result['rank']}")
                                print(f"\n{'â”€' * 70}")
                                print(f"âœ… ì„±ê³µ! ({price_name} {base_price:,}ì› + {category_name})")
                                print(f"{'â”€' * 70}")
                                print(result['url'])
                                print(f"{'â”€' * 70}")
                            return result['url']
                        else:
                            timeout_count = 0
                            # ì •ìƒ ì‘ë‹µ (ìƒí’ˆ ìˆìŒ) ì‹œì—ë§Œ ì°¨ë‹¨ ì¹´ìš´í„° ë¦¬ì…‹
                            if result['total_products'] > 0:
                                block_count = 0
                                category_has_results = True
                            if verbose:
                                print(f"  Page {page}: {result['total_products']}ê°œ ìƒí’ˆ (ë¯¸ë°œê²¬)")

                            if result['total_products'] == 0:
                                if verbose:
                                    print(f"  â†’ ìƒí’ˆ ì—†ìŒ, ë‹¤ìŒ ì „ëµìœ¼ë¡œ")
                                break

                # ì´ ì¹´í…Œê³ ë¦¬ì—ì„œ ìƒí’ˆì´ í•œ ë²ˆë„ ì—†ì—ˆìœ¼ë©´ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ë„ ìŠ¤í‚µ
                if not category_has_results:
                    if verbose:
                        print(f"\n  âš ï¸ '{category_name}' ì¹´í…Œê³ ë¦¬ì— ê²°ê³¼ ì—†ìŒ â†’ í•˜ìœ„ ì¹´í…Œê³ ë¦¬ ìŠ¤í‚µ")
                    break

        # Phase 2: ê°€ê²©ë§Œ (ì¹´í…Œê³ ë¦¬ ì—†ì´)
        if verbose:
            print(f"\nğŸ’° Phase 2: ê°€ê²© í•„í„°ë§Œ")

        for strategy_idx, (min_p, max_p) in enumerate(price_strategies):
            if min_p == 0 and max_p == 0:
                continue  # í•„í„° ì—†ìŒì€ Phase 2ì—ì„œ ìŠ¤í‚µ

            # URL ë¯¸ë¦¬ ìƒì„± (ì¶œë ¥ìš©)
            preview_url = (
                f"https://www.coupang.com/np/search?"
                f"listSize=36&minPrice={min_p}&maxPrice={max_p}"
                f"&component=&sorter=scoreDesc&page=1"
                f"&q={quote(keyword)}"
            )

            if verbose:
                print(f"\n[2-{strategy_idx + 1}] {min_p:,}ì› ~ {max_p:,}ì›")
                print(f"  URL: {preview_url}")

            for page in range(1, 4):
                result = search_with_filter(
                    keyword, product_id, min_p, max_p,
                    cookies, fingerprint, proxy, page,
                    component=None
                )

                if result.get('error'):
                    error = result['error']
                    is_blocked = result.get('blocked', False)

                    if is_blocked:
                        block_count += 1
                        if verbose:
                            print(f"  Page {page}: ğŸš« ì°¨ë‹¨ ({error[:40]}) [{block_count}/2]")
                        if block_count >= 2:
                            if verbose:
                                print(f"  âš ï¸ ì°¨ë‹¨ {block_count}íšŒ â†’ ì¿ í‚¤ ë§Œë£Œë¡œ ì¤‘ë‹¨")
                            return None
                    elif 'timed out' in error.lower() or 'curl: (28)' in error or 'curl: (7)' in error:
                        timeout_count += 1
                        if verbose:
                            print(f"  Page {page}: âŒ {error[:60]}")
                        if timeout_count >= 3:
                            if verbose:
                                print(f"  âš ï¸ íƒ€ì„ì•„ì›ƒ {timeout_count}íšŒ â†’ í”„ë¡ì‹œ ë¬¸ì œë¡œ ì¤‘ë‹¨")
                            return None
                    else:
                        if verbose:
                            print(f"  Page {page}: âŒ {error[:60]}")
                    break
                elif result['found']:
                    if verbose:
                        print(f"  Page {page}: âœ… ë°œê²¬! Rank #{result['rank']}")
                        print(f"\n{'â”€' * 70}")
                        print(f"âœ… ì„±ê³µ! ({price_name} {base_price:,}ì› ê¸°ì¤€)")
                        print(f"{'â”€' * 70}")
                        print(result['url'])
                        print(f"{'â”€' * 70}")
                    return result['url']
                else:
                    timeout_count = 0
                    # ì •ìƒ ì‘ë‹µ (ìƒí’ˆ ìˆìŒ) ì‹œì—ë§Œ ì°¨ë‹¨ ì¹´ìš´í„° ë¦¬ì…‹
                    if result['total_products'] > 0:
                        block_count = 0
                    if verbose:
                        print(f"  Page {page}: {result['total_products']}ê°œ ìƒí’ˆ (ë¯¸ë°œê²¬)")

                    if result['total_products'] == 0:
                        if verbose:
                            print(f"  â†’ ìƒí’ˆ ì—†ìŒ, ë‹¤ìŒ ì „ëµìœ¼ë¡œ")
                        break

    if verbose:
        print(f"\nâŒ ëª¨ë“  ì „ëµ ì‹¤íŒ¨")
    return None


def run_filter(args):
    """í•„í„° URL íƒìƒ‰ ì‹¤í–‰

    work APIì—ì„œ í• ë‹¹ë°›ì€ ìƒí’ˆì— ëŒ€í•´ í•„í„° URLì„ ì°¾ëŠ”ë‹¤.
    """
    print("=" * 70)
    print("í•„í„° URL íƒìƒ‰ [filter]")
    print("=" * 70)

    # 1. ì‘ì—… í• ë‹¹ ë°›ê¸° (rank íƒ€ì… ì‚¬ìš©)
    work_id = getattr(args, 'id', None)
    if work_id:
        print(f"\nğŸ“¥ ì‘ì—… ì¡°íšŒ (ID: {work_id})...")
    else:
        print(f"\nğŸ“¥ ì‘ì—… í• ë‹¹ ìš”ì²­...")

    allocation = allocate_work(work_id=work_id, work_type='rank')
    if not allocation:
        print("âŒ ì‘ì—… ì—†ìŒ" if not work_id else f"âŒ ID {work_id} ì‘ì—… ì—†ìŒ")
        return None

    # í• ë‹¹ ì‘ë‹µ JSON ì¶œë ¥
    print(f"{'â”€' * 60}")
    print(json.dumps(allocation, ensure_ascii=False, indent=2))
    print(f"{'â”€' * 60}")

    progress_id = allocation['progress_id']
    keyword = allocation['keyword']
    product_id = str(allocation['product_id'])
    item_id = allocation.get('item_id')
    vendor_item_id = allocation.get('vendor_item_id')
    allocated_proxy = allocation.get('proxy')
    external_ip = allocation.get('external_ip')

    # 2. ì¿ í‚¤ ì°¾ê¸°
    if external_ip:
        target_subnet = get_subnet(external_ip)
        print(f"\nğŸ” ì¿ í‚¤ íƒìƒ‰ (ì„œë¸Œë„·: {target_subnet}.*)")

        bound = get_bound_cookie(min_remain=30, max_age_minutes=60, target_subnet=target_subnet)
        if not bound:
            print(f"  âš ï¸ ì„œë¸Œë„· ë§¤ì¹­ ì¿ í‚¤ ì—†ìŒ - ì¼ë°˜ ì¿ í‚¤ ì‚¬ìš©")
            bound = get_bound_cookie(min_remain=30, max_age_minutes=60)

        if not bound:
            print("âŒ ì‚¬ìš© ê°€ëŠ¥í•œ ì¿ í‚¤ ì—†ìŒ")
            return None

        cookie_record = bound['cookie_record']
        cookies = bound['cookies']
        proxy = f"socks5://{allocated_proxy}"

        match_type = 'exact' if get_subnet(cookie_record['proxy_ip']) == target_subnet else 'fallback'
        print(f"  âœ… ì¿ í‚¤ ID: {cookie_record['id']} ({match_type})")
        print(f"     ì¿ í‚¤ IP: {cookie_record['proxy_ip']}")
    else:
        bound = get_bound_cookie(min_remain=30, max_age_minutes=60)
        if not bound:
            print("âŒ IP ë°”ì¸ë”© ë§¤ì¹­ ì‹¤íŒ¨")
            return None

        cookie_record = bound['cookie_record']
        cookies = bound['cookies']
        proxy = bound['proxy']
        print(f"  âœ… ì¿ í‚¤ ID: {cookie_record['id']} (auto)")

    # 3. í•‘ê±°í”„ë¦°íŠ¸
    fingerprint = get_random_fingerprint(verified_only=True)
    if not fingerprint:
        print("âŒ í•‘ê±°í”„ë¦°íŠ¸ ì—†ìŒ")
        return None

    print(f"\níƒ€ê²Ÿ: {product_id}")
    print(f"ê²€ìƒ‰ì–´: {keyword}")
    print(f"TLS: Chrome {fingerprint['chrome_major']}")
    print(f"í”„ë¡ì‹œ: {proxy}")

    # 4. ìƒí’ˆ ê°€ê²© ì¡°íšŒ (ì§ì ‘ ì ‘ì†)
    print(f"\n[{timestamp()}] ìƒí’ˆ ì •ë³´ ì¡°íšŒ...")

    direct_result = direct_access_product(
        product_id, item_id, vendor_item_id,
        cookies, fingerprint, proxy,
        save_html=False, verbose=True
    )

    if not direct_result['success']:
        print(f"âŒ ìƒí’ˆ ì¡°íšŒ ì‹¤íŒ¨: {direct_result.get('error')}")
        return None

    product_data = direct_result.get('productData', {})
    if not product_data:
        print("âŒ ìƒí’ˆ ë°ì´í„° ì—†ìŒ")
        return None

    api_data = to_api_response(product_data)
    price = api_data.get('price')  # í• ì¸ê°€ (ì‹œê°„ëŒ€ íŠ¹ê°€ ë“±)
    sales_price = api_data.get('salesPrice')  # ì¿ íŒ¡íŒë§¤ê°€ (type: SALES) - í•„í„° ê¸°ì¤€!
    original_price = api_data.get('originalPrice')  # ì›ê°€ (ì·¨ì†Œì„  ê°€ê²©)
    categories = api_data.get('categories', [])

    # í•„í„°ì— ì‚¬ìš©í•  ê°€ê²©: ì¿ íŒ¡íŒë§¤ê°€ ìš°ì„  (í• ì¸ê°€ëŠ” í•„í„° ì¡°ê±´ì— ì•ˆ ë§ëŠ” ê²½ìš°ê°€ ë§ìŒ)
    filter_price = sales_price or price or original_price

    if not filter_price:
        print("âŒ ê°€ê²© ì •ë³´ ì—†ìŒ")
        return None

    print(f"  ìƒí’ˆëª…: {api_data.get('title', '?')[:40]}...")
    if original_price and original_price != sales_price:
        print(f"  ì›ê°€: {original_price:,}ì› (ì·¨ì†Œì„ )")
    if sales_price:
        print(f"  ì¿ íŒ¡íŒë§¤ê°€: {sales_price:,}ì› â† í•„í„° ê¸°ì¤€")
    if price and price != sales_price:
        print(f"  í• ì¸ê°€: {price:,}ì› (ì‹œê°„ëŒ€ íŠ¹ê°€)")
    if categories:
        cat_names = ' > '.join([c.get('name', '?') for c in categories])
        print(f"  ì¹´í…Œê³ ë¦¬: {cat_names}")

    # 5. ì¿ í‚¤ í†µê³„ ì—…ë°ì´íŠ¸ (ì§ì ‘ ì ‘ì† ì„±ê³µ)
    update_cookie_stats(cookie_record['id'], True)

    # 6. í•„í„° URL íƒìƒ‰ (ì¿ íŒ¡íŒë§¤ê°€ë§Œ ì‚¬ìš© - í• ì¸ê°€ëŠ” í•„í„°ì— ì•ˆ ë§ìŒ)
    filter_url = find_filter_url(
        keyword, product_id, filter_price,  # ì¿ íŒ¡íŒë§¤ê°€ë¥¼ ë©”ì¸ ê°€ê²©ìœ¼ë¡œ
        cookies, fingerprint, proxy,
        categories=categories,
        original_price=None,  # í• ì¸ê°€/ì›ê°€ëŠ” ì‹œë„í•˜ì§€ ì•ŠìŒ
        verbose=True
    )

    # 7. ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 70)
    print("ê²°ê³¼")
    print("=" * 70)

    if filter_url:
        print(f"\nâœ… í•„í„° URL ë°œê²¬!")
        print(f"Progress ID: {progress_id}")
        print(f"ìƒí’ˆ: {product_id}")
        if sales_price:
            print(f"ì¿ íŒ¡íŒë§¤ê°€: {sales_price:,}ì›")
        else:
            print(f"ê°€ê²©: {filter_price:,}ì›")
        print(f"\nURL:\n{filter_url}")
    else:
        print(f"\nâŒ í•„í„° URLì„ ì°¾ì§€ ëª»í•¨")
        print(f"Progress ID: {progress_id}")
        print(f"ìƒí’ˆ: {product_id}")

    return {
        'progress_id': progress_id,
        'product_id': product_id,
        'keyword': keyword,
        'price': price,
        'filter_url': filter_url,
        'cookie_id': cookie_record['id']
    }


# ============================================================================
# ë³‘ë ¬ ë¬´í•œ ì‹¤í–‰ ëª¨ë“œ
# ============================================================================

# ì „ì—­ ì·¨ì†Œ í”Œë˜ê·¸
_cancelled = False
_stats_lock = threading.Lock()


def get_display_width(text):
    """ë¬¸ìì—´ì˜ ì‹¤ì œ í‘œì‹œ í­ ê³„ì‚° (í•œê¸€=2, ì˜ë¬¸=1)"""
    width = 0
    for char in text:
        if unicodedata.east_asian_width(char) in ('F', 'W'):
            width += 2
        else:
            width += 1
    return width


def pad_to_width(text, width):
    """ì§€ì •ëœ í­ì— ë§ê²Œ íŒ¨ë”© ì¶”ê°€"""
    current_width = get_display_width(text)
    if current_width >= width:
        return text
    return text + ' ' * (width - current_width)


def run_single_work(task_id, args):
    """ë‹¨ì¼ ì‘ì—… ì‹¤í–‰ (ThreadPoolExecutorìš©)"""
    global _cancelled
    work_type = getattr(args, 'type', 'rank')

    if _cancelled:
        return {
            'task_id': task_id,
            'status': 'cancelled',
            'found': False,
            'blocked': False,
            'progress_id': None,
            'rank': None,
            'keyword': None,
            'cookie_id': None,
            'proxy_ip': None
        }

    try:
        # ì‘ì—… í• ë‹¹
        allocation = allocate_work(work_type=work_type)
        if not allocation:
            return {
                'task_id': task_id,
                'status': 'no_work',
                'found': False,
                'blocked': False,
                'progress_id': None,
                'rank': None,
                'keyword': None,
                'cookie_id': None,
                'proxy_ip': None
            }

        progress_id = allocation['progress_id']
        keyword = allocation['keyword']
        product_id = str(allocation['product_id'])
        item_id = allocation.get('item_id')
        vendor_item_id = allocation.get('vendor_item_id')
        allocated_proxy = allocation.get('proxy')
        external_ip = allocation.get('external_ip')

        # ì¿ í‚¤ ì°¾ê¸°
        bound = None
        if external_ip:
            target_subnet = get_subnet(external_ip)
            bound = get_bound_cookie(min_remain=30, max_age_minutes=60, target_subnet=target_subnet)
            if not bound:
                bound = get_bound_cookie(min_remain=30, max_age_minutes=60)

        if not bound:
            report_result(progress_id, allocated_proxy or '', external_ip or '', 'failed', work_type=work_type)
            return {
                'task_id': task_id,
                'status': 'no_cookie',
                'found': False,
                'blocked': False,
                'progress_id': progress_id,
                'rank': None,
                'keyword': keyword,
                'cookie_id': None,
                'proxy_ip': external_ip
            }

        cookie_record = bound['cookie_record']
        cookies = bound['cookies']
        proxy = f"socks5://{allocated_proxy}" if allocated_proxy else bound['proxy']

        # ì¿ í‚¤ ìƒì„¸ ì •ë³´ ì¶”ì¶œ (DB ì¿¼ë¦¬ í•„ë“œëª…: created_age_seconds, last_success_age_seconds)
        cookie_info = {
            'id': cookie_record['id'],
            'init_status': cookie_record.get('init_status', '?'),
            'source': cookie_record.get('source', '?'),
            'chrome_version': cookie_record.get('chrome_version', '?'),
            'proxy_ip': cookie_record.get('proxy_ip', ''),
            'created_age': cookie_record.get('created_age_seconds', 0),  # ì´ˆ ë‹¨ìœ„
            'last_success_age': cookie_record.get('last_success_age_seconds'),  # ì´ˆ ë‹¨ìœ„ (None ê°€ëŠ¥)
            'success_count': cookie_record.get('success_count', 0),
            'fail_count': cookie_record.get('fail_count', 0),
        }

        # í•‘ê±°í”„ë¦°íŠ¸
        fingerprint = get_random_fingerprint(verified_only=True)
        if not fingerprint:
            report_result(progress_id, allocated_proxy or '', external_ip or '', 'failed', work_type=work_type)
            return {
                'task_id': task_id,
                'status': 'no_fingerprint',
                'found': False,
                'blocked': False,
                'progress_id': progress_id,
                'rank': None,
                'keyword': keyword,
                'cookie_id': cookie_record['id'],
                'proxy_ip': external_ip
            }

        # ê²€ìƒ‰ ì‹¤í–‰
        max_page = getattr(args, 'max_page', 13)
        result = search_product(
            keyword,
            product_id,
            cookies,
            fingerprint,
            proxy,
            max_page=max_page,
            verbose=False,  # ë³‘ë ¬ ëª¨ë“œì—ì„œëŠ” ìƒì„¸ ì¶œë ¥ ë”
            save_html=False
        )

        found = result['found']
        blocked = result['blocked']

        # ê²°ê³¼ ë³´ê³ 
        report_rank = None
        report_info = None

        if found:
            report_rank = result['actual_rank']

            # í´ë¦­
            if not getattr(args, 'no_click', False):
                ids = extract_ids_from_url(found['url'])
                product_info = {
                    'productId': found['productId'],
                    'url': found['url'],
                    'rank': found['rank'],
                    'itemId': ids['itemId'],
                    'vendorItemId': ids['vendorItemId']
                }
                search_url = f'https://www.coupang.com/np/search?q={quote(keyword)}'
                click_result = click_product(
                    product_info, search_url, cookies, fingerprint, proxy,
                    verbose=False,  # ë³‘ë ¬ ëª¨ë“œì—ì„œ ìƒì„¸ ì¶œë ¥ ë”
                    save_html=False
                )
                if click_result['success'] and click_result.get('productData'):
                    report_info = build_info_data(to_api_response(click_result['productData']))

        elif not blocked:
            # ë¯¸ë°œê²¬ vs ê²€ìƒ‰ì˜¤ë¥˜ êµ¬ë¶„
            search_count = len(result.get('all_products', []))
            page_errors = result.get('page_errors', [])
            no_results = result.get('no_results', False)  # ì¿ íŒ¡ "ê²€ìƒ‰ê²°ê³¼ ì—†ìŒ" ì‘ë‹µ

            if no_results:
                # ì¿ íŒ¡ì´ "ê²€ìƒ‰ê²°ê³¼ ì—†ìŒ" ì‘ë‹µ = ì •ìƒì ì¸ ë¯¸ë°œê²¬
                report_rank = 0
            elif search_count == 0 and page_errors:
                # ê²€ìƒ‰ëœ ìƒí’ˆ 0ê°œ + ì—ëŸ¬ ìˆìŒ = í”„ë¡ì‹œ ì˜¤ë¥˜ (ì§ì ‘ ì ‘ì† ì‹œë„ ì•ˆí•¨)
                blocked = True  # ë°”ë¡œ failed ì²˜ë¦¬
            else:
                # ê²€ìƒ‰í–ˆì§€ë§Œ íƒ€ê²Ÿ ìƒí’ˆ ì—†ìŒ = rank 0
                report_rank = 0

            # ì§ì ‘ ì ‘ì† (ê²€ìƒ‰ ì˜¤ë¥˜ê°€ ì•„ë‹ ë•Œë§Œ)
            if not blocked and not getattr(args, 'no_click', False):
                direct_result = direct_access_product(
                    product_id, item_id, vendor_item_id,
                    cookies, fingerprint, proxy,
                    save_html=False,
                    verbose=False  # ë³‘ë ¬ ëª¨ë“œì—ì„œ ìƒì„¸ ì¶œë ¥ ë”
                )
                if direct_result['success'] and direct_result.get('productData'):
                    report_info = build_info_data(to_api_response(direct_result['productData']))

        # ì¿ í‚¤ í†µê³„ ì—…ë°ì´íŠ¸
        is_success = not blocked
        update_cookie_stats(cookie_record['id'], is_success)
        update_cookie_data(cookie_record['id'], result.get('response_cookies_full', []))

        # ê²°ê³¼ ë³´ê³ 
        report_status = 'failed' if blocked else 'success'
        report_result(
            progress_id=progress_id,
            proxy=allocated_proxy or '',
            external_ip=external_ip or '',
            status=report_status,
            rank=report_rank,
            info=report_info,
            work_type=work_type
        )

        # í˜ì´ì§€ ì—ëŸ¬ ìš”ì•½ (ì°¨ë‹¨ ì›ì¸ ë¶„ì„ìš©)
        page_errors = result.get('page_errors', [])
        error_summary = ''
        if page_errors:
            # P1:CHALLENGE_1234B, P2:STATUS_403 í˜•ì‹
            error_parts = [f"P{e['page']}:{e['error'][:20]}" for e in page_errors[:3]]
            error_summary = ', '.join(error_parts)

        return {
            'task_id': task_id,
            'status': 'success',
            'found': bool(found),
            'blocked': blocked,
            'progress_id': progress_id,
            'rank': result.get('actual_rank'),
            'keyword': keyword,
            'cookie_id': cookie_record['id'],
            'proxy_ip': external_ip or cookie_record.get('proxy_ip', ''),
            # ìƒì„¸ ì •ë³´ ì¶”ê°€
            'tls_version': fingerprint.get('chrome_major', '?'),
            'cookie_info': cookie_info,
            'search_count': len(result.get('all_products', [])),
            'error_summary': error_summary,
            'block_error': result.get('block_error', ''),
        }

    except Exception as e:
        return {
            'task_id': task_id,
            'status': 'error',
            'error': str(e)[:100],
            'found': False,
            'blocked': False,
            'progress_id': None,
            'rank': None,
            'keyword': None,
            'cookie_id': None,
            'proxy_ip': None,
            'tls_version': None,
            'cookie_info': None,
            'search_count': 0,
            'error_summary': '',
            'block_error': '',
        }


def run_work_loop(args):
    """ë³‘ë ¬ ì‘ì—… ì‹¤í–‰ (íšŸìˆ˜ ì œí•œ ë˜ëŠ” ë¬´í•œ)

    Args:
        args.count (-n): ì‹¤í–‰ íšŸìˆ˜ (0=ë¬´í•œ, ê¸°ë³¸: ë¬´í•œ)
        args.parallel (-p): ë™ì‹œ ì‹¤í–‰ ìˆ˜ (ê¸°ë³¸: 2)
        args.delay: ì‹¤í–‰ ê°„ê²© ì´ˆ (ê¸°ë³¸: 0)
    """
    global _cancelled
    _cancelled = False

    import time

    work_type = getattr(args, 'type', 'rank')
    count = getattr(args, 'count', 0)  # 0=ë¬´í•œ
    parallel = getattr(args, 'parallel', 2)
    delay = getattr(args, 'delay', 0)

    start_time = datetime.now()
    print("=" * 70)
    if count == 0:
        print(f"ë³‘ë ¬ ì‘ì—… ì‹¤í–‰ [{work_type}] - ë¬´í•œ ë£¨í”„")
    else:
        print(f"ë³‘ë ¬ ì‘ì—… ì‹¤í–‰ [{work_type}] - {count}íšŒ")
    print("=" * 70)
    print(f"ì‹œì‘: {start_time.strftime('%H:%M:%S.%f')[:12]}")
    count_str = "ë¬´í•œ" if count == 0 else f"{count}íšŒ"
    print(f"íƒ€ì…: {work_type} | íšŸìˆ˜: {count_str} | ë³‘ë ¬: {parallel} | ë”œë ˆì´: {delay}ì´ˆ")
    print(f"ğŸ’¡ Ctrl+Cë¡œ ì¢…ë£Œ")
    print("=" * 70)

    # í†µê³„
    stats = {
        'total': 0,
        'found': 0,
        'not_found': 0,
        'blocked': 0,
        'error': 0,
        'no_work': 0,
        'cancelled': 0
    }

    # Ctrl+C í•¸ë“¤ëŸ¬
    def signal_handler(sig, frame):
        global _cancelled
        if not _cancelled:
            _cancelled = True
            print("\n\nğŸ›‘ ì¤‘ë‹¨ ìš”ì²­... ì‹¤í–‰ ì¤‘ì¸ ì‘ì—… ì™„ë£Œ ëŒ€ê¸°...")

    signal.signal(signal.SIGINT, signal_handler)

    task_id = 0
    submitted_count = 0  # ì œì¶œëœ ì‘ì—… ìˆ˜ (íšŸìˆ˜ ì œí•œìš©)

    try:
        with ThreadPoolExecutor(max_workers=parallel) as executor:
            futures = {}

            # ì´ˆê¸° ì‘ì—… ì œì¶œ (íšŸìˆ˜ ì œí•œ ê³ ë ¤)
            initial_submit = parallel if count == 0 else min(parallel, count)
            for i in range(initial_submit):
                task_id += 1
                submitted_count += 1
                futures[executor.submit(run_single_work, task_id, args)] = task_id

            while futures and not _cancelled:
                # ì™„ë£Œëœ ì‘ì—… ì²˜ë¦¬
                done_futures = [f for f in futures if f.done()]

                for future in done_futures:
                    tid = futures.pop(future)
                    result = future.result()

                    # ì·¨ì†Œëœ ì‘ì—…
                    if result['status'] == 'cancelled':
                        stats['cancelled'] += 1
                        continue

                    stats['total'] += 1

                    # ìƒíƒœë³„ í†µê³„ ë° ì¶œë ¥
                    now = datetime.now().strftime('%H:%M:%S.%f')[:12]
                    progress_str = f"[{stats['total']}/{count}]" if count > 0 else f"[{stats['total']}]"

                    if result['status'] == 'no_work':
                        stats['no_work'] += 1
                        print(f"[{now}] {progress_str} â¸ï¸  ì‘ì—… ì—†ìŒ")
                    elif result['status'] == 'error':
                        stats['error'] += 1
                        print(f"[{now}] {progress_str} âŒ ì—ëŸ¬: {result.get('error', '?')}")
                    else:
                        # ê³µí†µ ì •ë³´ ì¶”ì¶œ
                        keyword = result.get('keyword', '?')
                        proxy_ip = result.get('proxy_ip', '?')
                        subnet = '.'.join(proxy_ip.split('.')[:3]) if proxy_ip else '?'
                        progress_id = result.get('progress_id', '?')
                        tls_ver = result.get('tls_version', '?')

                        # ì¿ í‚¤ ì •ë³´
                        cookie_info = result.get('cookie_info') or {}
                        cookie_id = cookie_info.get('id', '?')
                        init_status = cookie_info.get('init_status', '?')
                        source = cookie_info.get('source', '?')
                        cookie_ver = cookie_info.get('chrome_version', '?')
                        created_age = cookie_info.get('created_age', 0)
                        last_success_age = cookie_info.get('last_success_age')

                        # source ì•½ì–´ (localâ†’L, pg_syncâ†’P)
                        source_map = {'local': 'L', 'pg_sync': 'P'}
                        source_short = source_map.get(source, '?')

                        # ì¿ í‚¤ ë²„ì „ ë©”ì´ì € (131.0.6778.264 â†’ 131)
                        cookie_major = str(cookie_ver).split('.')[0] if cookie_ver != '?' else '?'

                        # ê²½ê³¼ ì‹œê°„ (C=ìƒì„±, S=ìµœì¢…ì„±ê³µ)
                        age_str = f"C{created_age//60}m"
                        if last_success_age is not None:
                            age_str += f"/S{last_success_age//60}m"

                        # ìƒíƒœë³„ ì²˜ë¦¬
                        if result['blocked']:
                            stats['blocked'] += 1
                            status = "ğŸš«ì°¨ë‹¨"
                            rank_str = ""
                            # ì°¨ë‹¨ ì›ì¸ í‘œì‹œ
                            block_error = result.get('block_error', '')[:25]
                            extra_info = f"[{block_error}]" if block_error else ""
                        elif result['found']:
                            stats['found'] += 1
                            rank = result.get('rank', 0)
                            status = "âœ…ë°œê²¬"
                            rank_str = f"#{rank}"
                            extra_info = ""
                        else:
                            stats['not_found'] += 1
                            status = "âŒë¯¸ë°œê²¬"
                            rank_str = ""
                            # ê²€ìƒ‰ ìˆ˜ ë° ì—ëŸ¬ í‘œì‹œ
                            search_count = result.get('search_count', 0)
                            error_summary = result.get('error_summary', '')
                            if error_summary:
                                extra_info = f"({search_count}ê°œ) [{error_summary}]"
                            else:
                                extra_info = f"({search_count}ê°œ)"

                        # init_statusê°€ ë¹„ì •ìƒì¼ ë•Œë§Œ í‘œì‹œ (success, defaultëŠ” ì •ìƒ)
                        normal_statuses = {'success', 'default', None}
                        init_info = f"({init_status})" if init_status not in normal_statuses else ""

                        # ê³ ì • ë„ˆë¹„ ì •ë ¬
                        keyword_pad = pad_to_width(keyword[:12], 12)
                        age_pad = age_str.rjust(12)
                        print(f"[{now}] {progress_str:<8} {status} {rank_str:>4} | {keyword_pad} | P#{progress_id:<6} | {cookie_id:>6} | [{source_short}]v{cookie_major:>3}/{tls_ver:<3} | {age_pad} | {subnet:<12} {extra_info}{init_info}")

                    # ìƒˆ ì‘ì—… ì œì¶œ (íšŸìˆ˜ ì œí•œ ë˜ëŠ” ë¬´í•œ)
                    can_submit = count == 0 or submitted_count < count
                    if not _cancelled and can_submit:
                        if delay > 0:
                            time.sleep(delay)
                        task_id += 1
                        submitted_count += 1
                        futures[executor.submit(run_single_work, task_id, args)] = task_id

                # ì ì‹œ ëŒ€ê¸° (CPU ì‚¬ìš©ëŸ‰ ì ˆê°)
                if not done_futures:
                    time.sleep(0.1)

    except KeyboardInterrupt:
        pass

    # ê²°ê³¼ ìš”ì•½
    end_time = datetime.now()
    elapsed = (end_time - start_time).total_seconds()

    print("\n" + "=" * 70)
    print("ê²°ê³¼ ìš”ì•½")
    print("=" * 70)
    print(f"ì´ ì‹¤í–‰: {stats['total']}íšŒ | ì†Œìš”: {elapsed:.1f}ì´ˆ")
    if stats['total'] > 0:
        found_rate = stats['found'] * 100 // stats['total']
        print(f"âœ… ë°œê²¬: {stats['found']}íšŒ ({found_rate}%)")
        print(f"âŒ ë¯¸ë°œê²¬: {stats['not_found']}íšŒ")
        print(f"ğŸš« ì°¨ë‹¨: {stats['blocked']}íšŒ")
        print(f"âš ï¸ ì—ëŸ¬: {stats['error']}íšŒ")
        if stats['no_work'] > 0:
            print(f"â¸ï¸ ì‘ì—…ì—†ìŒ: {stats['no_work']}íšŒ")
        if stats['cancelled'] > 0:
            print(f"ğŸ›‘ ì·¨ì†Œ: {stats['cancelled']}íšŒ")

    print(f"\nì™„ë£Œ: {end_time.strftime('%H:%M:%S.%f')[:12]}")

    return stats


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(description='ì‘ì—… í• ë‹¹ ê¸°ë°˜ ê²€ìƒ‰')
    parser.add_argument('--max-page', type=int, default=13, help='ìµœëŒ€ ê²€ìƒ‰ í˜ì´ì§€')
    parser.add_argument('--no-click', action='store_true', help='í´ë¦­ ê±´ë„ˆë›°ê¸°')
    parser.add_argument('-n', '--count', type=int, default=0, help='ì‹¤í–‰ íšŸìˆ˜ (0=ë¬´í•œ, ê¸°ë³¸: ë¬´í•œ)')
    parser.add_argument('-p', '--parallel', type=int, default=2, help='ë³‘ë ¬ ìˆ˜ (ê¸°ë³¸: 2)')
    parser.add_argument('--delay', type=float, default=0, help='ì‹¤í–‰ ê°„ê²© ì´ˆ (ê¸°ë³¸: 0)')
    parser.add_argument('--id', type=int, help='íŠ¹ì • ì‘ì—… ID (1íšŒ ì‹¤í–‰)')

    args = parser.parse_args()

    if args.id:
        run_work(args)
    else:
        run_work_loop(args)

"""
ìƒí’ˆ ê²€ìƒ‰ ëª…ë ¹ì–´ (ë¦¬íŒ©í† ë§ ë²„ì „)

í•µì‹¬ ì•Œê³ ë¦¬ì¦˜:
  ëœë¤ IP (ë°”ì¸ë”©) + ëœë¤ ì¿ í‚¤ (/24 ë§¤ì¹­) + ëœë¤ TLS = ì„±ê³µ
"""

import json
import random
from datetime import datetime
from pathlib import Path
from urllib.parse import quote

import sys
from pathlib import Path
sys.path.insert(0, str(Path(__file__).parent.parent))

from common.db import execute_query
from common.proxy import get_bound_cookie, get_cookie_by_id, parse_cookie_data, get_subnet, update_cookie_stats, update_cookie_data, get_proxy_list
from common.fingerprint import get_fingerprint_by_version, get_random_fingerprint
from cffi.search import search_product
from cffi.click import click_product, extract_ids_from_url
from cffi.request import timestamp
from screenshot import save_html_with_urls, take_screenshot_from_saved

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ (lib/cffi/ â†’ ìƒìœ„ 2ë‹¨ê³„)
PROJECT_ROOT = Path(__file__).parent.parent.parent  # /home/tech/packet_coupang_v1

# ê¸°ë³¸ í…ŒìŠ¤íŠ¸ ìƒí’ˆ
DEFAULT_PRODUCT = {
    'product_id': '9024146312',
    'query': 'í˜¸ë°• ë‹¬ë¹›ì‹í˜œ'
}


def direct_access_product(product_id, item_id, vendor_item_id, cookies, fingerprint, proxy):
    """ìƒí’ˆ URL ì§ì ‘ ì ‘ì†ìœ¼ë¡œ ì •ë³´ ì¶”ì¶œ

    Args:
        product_id: ìƒí’ˆ ID
        item_id: ì•„ì´í…œ ID (ì—†ìœ¼ë©´ None)
        vendor_item_id: ë²¤ë” ì•„ì´í…œ ID (ì—†ìœ¼ë©´ None)
        cookies: ì¿ í‚¤ ë”•ì…”ë„ˆë¦¬
        fingerprint: í•‘ê±°í”„ë¦°íŠ¸ ë ˆì½”ë“œ
        proxy: í”„ë¡ì‹œ URL

    Returns:
        dict: {success, productData, response_cookies_full}
    """
    from cffi.request import make_request, parse_response_cookies
    from extractor.detail_extractor import extract_product_detail

    # URL êµ¬ì„±
    if item_id and vendor_item_id:
        url = f'https://www.coupang.com/vp/products/{product_id}?itemId={item_id}&vendorItemId={vendor_item_id}'
    else:
        url = f'https://www.coupang.com/vp/products/{product_id}'

    print(f"\n[{timestamp()}] ì§ì ‘ ì ‘ì†...")
    print(f"  URL: {url}")

    try:
        resp = make_request(url, cookies, fingerprint, proxy, referer='https://www.coupang.com/')
        size = len(resp.content)

        response_cookies, response_cookies_full = parse_response_cookies(resp)

        print(f"  Status: {resp.status_code} | Size: {size:,} bytes")

        if size > 100000:
            product_data = extract_product_detail(resp.text)

            if product_data:
                print(f"\n{'â”€' * 70}")
                print("ğŸ“¦ ì§ì ‘ ì ‘ì† ìƒí’ˆ ì •ë³´")
                print(f"{'â”€' * 70}")
                for key, value in product_data.items():
                    print(f"   {key}: {value}")
                print(f"{'â”€' * 70}")

            return {
                'success': True,
                'productData': product_data,
                'response_cookies_full': response_cookies_full,
                'size': size
            }
        else:
            print(f"  âŒ ì‘ë‹µ í¬ê¸° ë¶€ì¡± ({size:,} bytes)")
            return {
                'success': False,
                'error': f'INVALID_RESPONSE_{size}B',
                'response_cookies_full': response_cookies_full,
                'size': size
            }

    except Exception as e:
        print(f"  âŒ ì—ëŸ¬: {str(e)[:50]}")
        return {
            'success': False,
            'error': str(e)[:100],
            'response_cookies_full': [],
            'size': 0
        }


def run_search(args):
    """ìƒí’ˆ ê²€ìƒ‰ ì‹¤í–‰"""
    print("=" * 70)
    print("ìƒí’ˆ ê²€ìƒ‰")
    print("=" * 70)

    # IP ë°”ì¸ë”© + ì¿ í‚¤ ì„ íƒ
    if args.cookie_id:
        # íŠ¹ì • ì¿ í‚¤ ID ì§€ì •
        cookie_record = get_cookie_by_id(args.cookie_id)
        if not cookie_record:
            print(f"âŒ ì¿ í‚¤ ID {args.cookie_id} ì—†ìŒ")
            return None
        cookies = parse_cookie_data(cookie_record)

        # ì¿ í‚¤ì˜ IP ì„œë¸Œë„·ê³¼ ë§¤ì¹­ë˜ëŠ” í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ í”„ë¡ì‹œ ì°¾ê¸°
        if args.proxy:
            proxy = args.proxy
        else:
            cookie_subnet = get_subnet(cookie_record['proxy_ip'])
            proxies = get_proxy_list(min_remain=30)
            matching_proxy = None
            for p in proxies:
                if get_subnet(p.get('external_ip')) == cookie_subnet:
                    matching_proxy = f"socks5://{p['proxy']}"
                    break
            if matching_proxy:
                proxy = matching_proxy
                print(f"ğŸ“ ì¿ í‚¤ ID: {cookie_record['id']} (ì§€ì •) - ì„œë¸Œë„· ë§¤ì¹­ í”„ë¡ì‹œ ì‚¬ìš©")
                print(f"   ì¿ í‚¤ IP: {cookie_record['proxy_ip']} â†’ í”„ë¡ì‹œ ì„œë¸Œë„·: {cookie_subnet}.*")
            else:
                # ë§¤ì¹­ í”„ë¡ì‹œ ì—†ìœ¼ë©´ ì›ë˜ proxy_url ì‚¬ìš© (ê²½ê³  ì¶œë ¥)
                proxy = f"socks5://{cookie_record['proxy_url']}" if cookie_record['proxy_url'] else None
                print(f"âš ï¸ ì¿ í‚¤ ID: {cookie_record['id']} (ì§€ì •) - ì„œë¸Œë„· ë§¤ì¹­ í”„ë¡ì‹œ ì—†ìŒ!")
                print(f"   ì¿ í‚¤ IP: {cookie_record['proxy_ip']} - ì›ë˜ í”„ë¡ì‹œ ì‚¬ìš© (ì°¨ë‹¨ ê°€ëŠ¥ì„± ë†’ìŒ)")
    else:
        # IP ë°”ì¸ë”© ìë™ ì„ íƒ
        print("ğŸ” IP ë°”ì¸ë”© ì¿ í‚¤ íƒìƒ‰...")

        # ì œì™¸í•  ì„œë¸Œë„· íŒŒì‹±
        exclude_subnets = []
        if hasattr(args, 'exclude_subnets') and args.exclude_subnets:
            exclude_subnets = [s.strip() for s in args.exclude_subnets.split(',') if s.strip()]
            if exclude_subnets:
                print(f"  â›” ì œì™¸ ì„œë¸Œë„·: {len(exclude_subnets)}ê°œ")

        bound = get_bound_cookie(min_remain=30, max_age_minutes=60, exclude_subnets=exclude_subnets)
        if not bound:
            print("âŒ IP ë°”ì¸ë”© ë§¤ì¹­ ì‹¤íŒ¨")
            return None

        cookie_record = bound['cookie_record']
        cookies = bound['cookies']
        proxy = args.proxy or bound['proxy']

        match_icon = "âœ…" if bound['match_type'] == 'exact' else "ğŸ”—"
        print(f"  {match_icon} ì¿ í‚¤ ID: {cookie_record['id']} ({bound['match_type']})")
        print(f"     IP: {bound['external_ip']} (ì„œë¸Œë„·: {get_subnet(bound['external_ip'])}.*)")
        # ê²½ê³¼ ì‹œê°„ í‘œì‹œ
        created_age = cookie_record.get('created_age_seconds', 0) or 0
        last_success_age = cookie_record.get('last_success_age_seconds')
        last_success_str = f"{last_success_age}ì´ˆ" if last_success_age else "ì—†ìŒ"
        print(f"     ê²½ê³¼: ìƒì„± {created_age}ì´ˆ | ìµœì¢…ì„±ê³µ {last_success_str}")
        print(f"     ìƒíƒœ: {cookie_record.get('init_status', '?')} | ì†ŒìŠ¤: {cookie_record.get('source', '?')} | ì¿ í‚¤ë²„ì „: {cookie_record.get('chrome_version', '?')}")

    # TLS í•‘ê±°í”„ë¦°íŠ¸ ì„ íƒ (ê²€ì¦ëœ ë²„ì „ ì¤‘ ëœë¤)
    fingerprint = get_random_fingerprint(verified_only=True)
    if not fingerprint:
        print("âŒ í•‘ê±°í”„ë¦°íŠ¸ ì—†ìŒ")
        return None

    print(f"\níƒ€ê²Ÿ: {args.product_id}")
    print(f"ê²€ìƒ‰ì–´: {args.query}")
    print(f"TLS: Chrome {fingerprint['chrome_major']} (custom)")
    print(f"í”„ë¡ì‹œ: {proxy}")
    print("=" * 70)

    # ê²€ìƒ‰ ì‹¤í–‰
    save_html = args.screenshot
    start_time = datetime.now()
    result = search_product(
        args.query,
        args.product_id,
        cookies,
        fingerprint,
        proxy,
        max_page=args.max_page,
        verbose=True,
        save_html=save_html
    )

    search_time = (datetime.now() - start_time).total_seconds()

    # í˜ì´ì§€ ì—ëŸ¬ê°€ ìˆê³  ìƒí’ˆ ë¯¸ë°œê²¬ ì‹œ ì¬ì‹œë„ (curl íƒ€ì„ì•„ì›ƒ, TLS ì—ëŸ¬ ë“±)
    page_errors = result.get('page_errors', [])
    retry_errors = ['curl: (28)', 'curl: (35)', 'TLS connect error', 'Operation timed out']
    has_retry_error = any(
        any(err in e.get('error', '') for err in retry_errors)
        for e in page_errors
    )

    if not result['found'] and not result['blocked'] and has_retry_error and not args.cookie_id:
        print(f"\nğŸ”„ ë„¤íŠ¸ì›Œí¬ ì—ëŸ¬ ë°œìƒ - ë‹¤ë¥¸ í”„ë¡ì‹œë¡œ ì¬ì‹œë„...")

        # í˜„ì¬ ì„œë¸Œë„· ì œì™¸í•˜ê³  ìƒˆ ì¿ í‚¤ íƒìƒ‰
        current_subnet = get_subnet(cookie_record['proxy_ip'])
        retry_exclude = [current_subnet] if current_subnet else []
        if hasattr(args, 'exclude_subnets') and args.exclude_subnets:
            retry_exclude.extend([s.strip() for s in args.exclude_subnets.split(',') if s.strip()])

        retry_bound = get_bound_cookie(min_remain=30, max_age_minutes=60, exclude_subnets=retry_exclude)
        if retry_bound:
            retry_cookie_record = retry_bound['cookie_record']
            retry_cookies = retry_bound['cookies']
            retry_proxy = retry_bound['proxy']
            retry_fingerprint = get_random_fingerprint(verified_only=True)

            print(f"  âœ… ìƒˆ ì¿ í‚¤ ID: {retry_cookie_record['id']}")
            print(f"     IP: {retry_bound['external_ip']} (ì„œë¸Œë„·: {get_subnet(retry_bound['external_ip'])}.*)")

            # ì¬ì‹œë„ ê²€ìƒ‰
            retry_result = search_product(
                args.query,
                args.product_id,
                retry_cookies,
                retry_fingerprint,
                retry_proxy,
                max_page=args.max_page,
                verbose=True,
                save_html=save_html
            )

            # ì¬ì‹œë„ ì¿ í‚¤ í†µê³„ ì—…ë°ì´íŠ¸
            retry_success = not retry_result['blocked']
            update_cookie_stats(retry_cookie_record['id'], retry_success)

            if retry_result.get('response_cookies_full'):
                update_cookie_data(retry_cookie_record['id'], retry_result['response_cookies_full'])

            # ì¬ì‹œë„ ê²°ê³¼ê°€ ë” ì¢‹ìœ¼ë©´ êµì²´
            if retry_result['found'] or (not retry_result['blocked'] and not result['found']):
                result = retry_result
                cookie_record = retry_cookie_record
                cookies = retry_cookies
                fingerprint = retry_fingerprint
                proxy = retry_proxy
                search_time += (datetime.now() - start_time).total_seconds() - search_time
        else:
            print(f"  âš ï¸ ì¬ì‹œë„ìš© í”„ë¡ì‹œ ì—†ìŒ - ê±´ë„ˆëœ€")

    # ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 70)
    print("ê²°ê³¼")
    print("=" * 70)

    found = result['found']
    blocked = result['blocked']

    if found:
        print(f"\nâœ… ìƒí’ˆ ë°œê²¬")
        print(f"   í˜ì´ì§€: {found['page']}")
        print(f"   ìˆœìœ„: {result['actual_rank']}ë“± / {len(result['all_products'])}ê°œ")

        # ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¶”ì¶œëœ ìƒí’ˆ ì •ë³´ (ì „ì²´ í‘œì‹œ)
        print(f"\n{'â”€' * 70}")
        print("ğŸ“‹ ê²€ìƒ‰ ê²°ê³¼ ìƒí’ˆ ì •ë³´")
        print(f"{'â”€' * 70}")
        for key, value in found.items():
            if key not in ['_page']:  # ë‚´ë¶€ í‚¤ ì œì™¸
                print(f"   {key}: {value}")
        print(f"{'â”€' * 70}")

        # ìŠ¤í¬ë¦°ìƒ· ì²˜ë¦¬
        screenshot_path = None
        if save_html and result.get('found_html'):
            ts = datetime.now().strftime('%Y%m%d_%H%M%S')
            screenshot_dir = PROJECT_ROOT / 'screenshot'
            screenshot_dir.mkdir(parents=True, exist_ok=True)  # í´ë” ì—†ìœ¼ë©´ ìƒì„±
            html_path = screenshot_dir / f'search_{args.product_id}_{ts}.html'

            # 1ë‹¨ê³„: HTML + URL JSON ì €ì¥
            save_result = save_html_with_urls(
                result['found_html'],
                html_path,
                metadata={
                    'query': args.query,
                    'product_id': args.product_id,
                    'rank': result['actual_rank'],
                    'page': found['page'],
                    'timestamp': ts
                }
            )
            print(f"\nğŸ“„ HTML ì €ì¥: {save_result['html_path']}")

            # 2ë‹¨ê³„: ìŠ¤í¬ë¦°ìƒ· ìƒì„±
            print(f"ğŸ“¸ ìŠ¤í¬ë¦°ìƒ· ìƒì„± ì¤‘...")
            ss_result = take_screenshot_from_saved(html_path)
            if ss_result['success']:
                screenshot_path = ss_result['path']
                print(f"   âœ… {screenshot_path}")
                print(f"   í¬ê¸°: {ss_result['size']:,} bytes")
                print(f"   ì´ë¯¸ì§€: {ss_result['images_loaded']}/{ss_result['images_total']} ë¡œë“œ")
            else:
                print(f"   âŒ ìŠ¤í¬ë¦°ìƒ· ì‹¤íŒ¨: {ss_result.get('error')}")

        # í´ë¦­
        if not args.no_click:
            print(f"\n[{timestamp()}] ìƒí’ˆ í´ë¦­...")

            ids = extract_ids_from_url(found['url'])
            product_info = {
                'productId': found['productId'],
                'url': found['url'],
                'rank': found['rank'],
                'itemId': ids['itemId'],
                'vendorItemId': ids['vendorItemId']
            }

            search_url = f'https://www.coupang.com/np/search?q={quote(args.query)}'
            click_result = click_product(
                product_info, search_url, cookies, fingerprint, proxy
            )

            if not click_result['success']:
                print(f"  âŒ í´ë¦­ ì‹¤íŒ¨: {click_result.get('error')}")

    elif blocked:
        print(f"\nğŸš« ì°¨ë‹¨ë¨: {result['block_error']}")
    else:
        # í˜ì´ì§€ ì—ëŸ¬ê°€ ìˆìœ¼ë©´ í‘œì‹œ
        page_errors = result.get('page_errors', [])
        if page_errors:
            error_str = ', '.join([f"P{e['page']}:{e['error']}" for e in page_errors])
            print(f"\nâŒ ìƒí’ˆ ë¯¸ë°œê²¬ ({len(result['all_products'])}ê°œ ê²€ìƒ‰) | ì—ëŸ¬: {error_str}")
        else:
            print(f"\nâŒ ìƒí’ˆ ë¯¸ë°œê²¬ ({len(result['all_products'])}ê°œ ê²€ìƒ‰)")

        # ì§ì ‘ ì ‘ì†ìœ¼ë¡œ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ (--no-clickì´ ì•„ë‹ˆë©´ ì‹¤í–‰)
        if not args.no_click:
            item_id = product_info.get('item_id') if product_info else None
            vendor_item_id = product_info.get('vendor_item_id') if product_info else None

            direct_result = direct_access_product(
                args.product_id, item_id, vendor_item_id,
                cookies, fingerprint, proxy
            )

            # ì§ì ‘ ì ‘ì† ì‘ë‹µ ì¿ í‚¤ë„ ì—…ë°ì´íŠ¸ì— í¬í•¨
            if direct_result.get('response_cookies_full'):
                result['response_cookies_full'].extend(direct_result['response_cookies_full'])

            # ì§ì ‘ ì ‘ì† ì‹¤íŒ¨ ì‹œ ì¬ì‹œë„ (ìƒˆ ì¿ í‚¤/í”„ë¡ì‹œë¡œ)
            if not direct_result.get('success') and not args.cookie_id:
                print(f"\nğŸ”„ ì§ì ‘ì ‘ì† ì°¨ë‹¨ - ìƒˆ ì¿ í‚¤ë¡œ ì¬ì‹œë„...")

                # í˜„ì¬ ì„œë¸Œë„· ì œì™¸í•˜ê³  ìƒˆ ì¿ í‚¤ íƒìƒ‰
                current_subnet = get_subnet(cookie_record['proxy_ip'])
                retry_exclude = [current_subnet] if current_subnet else []
                if hasattr(args, 'exclude_subnets') and args.exclude_subnets:
                    retry_exclude.extend([s.strip() for s in args.exclude_subnets.split(',') if s.strip()])

                retry_bound = get_bound_cookie(min_remain=30, max_age_minutes=60, exclude_subnets=retry_exclude)
                if retry_bound:
                    retry_cookie_record = retry_bound['cookie_record']
                    retry_cookies = retry_bound['cookies']
                    retry_proxy = retry_bound['proxy']
                    retry_fingerprint = get_random_fingerprint(verified_only=True)

                    print(f"  âœ… ìƒˆ ì¿ í‚¤ ID: {retry_cookie_record['id']}")
                    print(f"     IP: {retry_bound['external_ip']} (ì„œë¸Œë„·: {get_subnet(retry_bound['external_ip'])}.*)")

                    direct_result = direct_access_product(
                        args.product_id, item_id, vendor_item_id,
                        retry_cookies, retry_fingerprint, retry_proxy
                    )

                    # ì¬ì‹œë„ ì¿ í‚¤ í†µê³„ ì—…ë°ì´íŠ¸
                    retry_success = direct_result.get('success', False)
                    update_cookie_stats(retry_cookie_record['id'], retry_success)

                    if direct_result.get('response_cookies_full'):
                        update_cookie_data(retry_cookie_record['id'], direct_result['response_cookies_full'])
                else:
                    print(f"  âŒ ì¬ì‹œë„ìš© ì¿ í‚¤ ì—†ìŒ")

    # í†µê³„ ì—…ë°ì´íŠ¸
    is_success = not blocked
    update_cookie_stats(cookie_record['id'], is_success)

    # ì¿ í‚¤ ë°ì´í„° ì—…ë°ì´íŠ¸ (í•„ìˆ˜)
    updated = update_cookie_data(cookie_record['id'], result.get('response_cookies_full', []))
    if updated > 0:
        print(f"\nğŸ’¾ ì¿ í‚¤ ì—…ë°ì´íŠ¸: {updated}ê°œ")

    # íŠ¸ë˜í”½ ì¶œë ¥
    total_bytes = result.get('total_bytes', 0)
    if total_bytes > 0:
        if total_bytes >= 1024 * 1024:
            traffic_str = f"{total_bytes / (1024 * 1024):.2f} MB"
        else:
            traffic_str = f"{total_bytes / 1024:.2f} KB"
        print(f"ğŸ“Š íŠ¸ë˜í”½: {traffic_str} | ì‹œê°„: {search_time:.1f}ì´ˆ")

    print(f"\nâœ… ì¿ í‚¤:{cookie_record['id']} | TLS:{fingerprint['chrome_major']}")

    return {
        'found': bool(found),
        'blocked': blocked,
        'cookie_id': cookie_record['id'],
        'fingerprint': fingerprint['chrome_major'],
        'search_time': search_time
    }


if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser()
    parser.add_argument('--product-id', default='9024146312')
    parser.add_argument('--query', default='í˜¸ë°• ë‹¬ë¹›ì‹í˜œ')
    parser.add_argument('--max-page', type=int, default=13)
    parser.add_argument('--no-click', action='store_true', help='í´ë¦­/ì§ì ‘ì ‘ì† ê±´ë„ˆë›°ê¸°')
    parser.add_argument('--cookie-id', type=int)
    parser.add_argument('--proxy')
    parser.add_argument('--screenshot', action='store_true', help='ìƒí’ˆ ë°œê²¬ ì‹œ ìŠ¤í¬ë¦°ìƒ· ì €ì¥')

    args = parser.parse_args()
    run_search(args)

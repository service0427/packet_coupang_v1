#!/usr/bin/env python3
"""
ìƒí’ˆ í´ë¦­ ì‹œ ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ëª¨ë‹ˆí„°ë§
- ê²€ìƒ‰ â†’ ìƒí’ˆ ì°¾ê¸° â†’ í´ë¦­ â†’ ëª¨ë“  ìš”ì²­ ì¶”ì 
"""

import os
import sys
import json
import time
from pathlib import Path
from datetime import datetime
from playwright.sync_api import sync_playwright

# Add lib directory to path
sys.path.insert(0, str(Path(__file__).parent.parent / 'lib'))
from db import execute_query

# Set DISPLAY for Xvfb
if 'DISPLAY' not in os.environ:
    os.environ['DISPLAY'] = ':99'

# íƒ€ê²Ÿ ìƒí’ˆ ì •ë³´
TARGET_PRODUCT = {
    'product_id': '9024146312',
    'query': 'í˜¸ë°• ë‹¬ë¹›ì‹í˜œ'
}

def get_latest_cookie():
    """DBì—ì„œ ìµœì‹  ì¿ í‚¤ ê°€ì ¸ì˜¤ê¸°"""
    rows = execute_query("""
        SELECT id, cookie_data, chrome_version, proxy_url, proxy_ip
        FROM cookies
        WHERE use_count = 0
        ORDER BY id DESC
        LIMIT 1
    """)
    if rows:
        row = rows[0]
        return {
            'id': row['id'],
            'cookie_data': json.loads(row['cookie_data']),
            'chrome_version': row['chrome_version'],
            'proxy_url': row['proxy_url'],
            'proxy_ip': row['proxy_ip']
        }
    return None

def monitor_product_click():
    """ìƒí’ˆ í´ë¦­ ëª¨ë‹ˆí„°ë§"""

    # ì¿ í‚¤ ê°€ì ¸ì˜¤ê¸°
    cookie_record = get_latest_cookie()
    if not cookie_record:
        print("âŒ ìœ íš¨í•œ ì¿ í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
        return

    # ìˆ˜ì§‘í•  ë°ì´í„°
    requests_log = []
    responses_log = []

    print("=" * 70)
    print("ìƒí’ˆ í´ë¦­ ë„¤íŠ¸ì›Œí¬ ëª¨ë‹ˆí„°ë§")
    print("=" * 70)
    # DBì—ëŠ” host:portë§Œ ì €ì¥
    db_proxy = cookie_record['proxy_url']
    proxy = f'socks5://{db_proxy}' if db_proxy else None

    print(f"ê²€ìƒ‰ì–´: {TARGET_PRODUCT['query']}")
    print(f"ìƒí’ˆ ID: {TARGET_PRODUCT['product_id']}")
    print(f"ì¿ í‚¤ ID: {cookie_record['id']}")
    print(f"Chrome: {cookie_record['chrome_version']}")
    print(f"í”„ë¡ì‹œ: {proxy}")
    print("=" * 70)

    with sync_playwright() as p:
        # Chrome ë²„ì „ì—ì„œ major ë²„ì „ ì¶”ì¶œ
        chrome_version = cookie_record['chrome_version']
        major_version = int(chrome_version.split('.')[0])

        # ì‹¤ì œ Chrome ë°”ì´ë„ˆë¦¬ ì°¾ê¸°
        chrome_dir = Path(__file__).parent.parent / 'chrome-versions' / 'files'
        chrome_path = None

        for d in chrome_dir.iterdir():
            if d.is_dir() and chrome_version in d.name:
                linux_path = d / 'chrome-linux64' / 'chrome'
                if linux_path.exists():
                    chrome_path = str(linux_path)
                    break

        if not chrome_path:
            print(f"âŒ Chrome {chrome_version} ë°”ì´ë„ˆë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return

        print(f"Chrome ë°”ì´ë„ˆë¦¬: {chrome_path}")

        # ë¸Œë¼ìš°ì € ì‹¤í–‰ (ì‹¤ì œ Chrome ì‚¬ìš©)
        browser = p.chromium.launch(
            executable_path=chrome_path,
            headless=False,
            args=[
                '--no-sandbox',
                '--disable-blink-features=AutomationControlled',
                '--no-first-run',
            ],
            proxy={'server': proxy} if proxy else None
        )

        context = browser.new_context(
            user_agent=f'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/{major_version}.0.0.0 Safari/537.36'
        )

        # ì¿ í‚¤ ì„¤ì •
        cookies_for_playwright = []
        for cookie in cookie_record['cookie_data']:
            pw_cookie = {
                'name': cookie['name'],
                'value': cookie['value'],
                'domain': cookie.get('domain', '.coupang.com'),
                'path': cookie.get('path', '/'),
            }
            cookies_for_playwright.append(pw_cookie)

        context.add_cookies(cookies_for_playwright)
        print(f"âœ… ì¿ í‚¤ {len(cookies_for_playwright)}ê°œ ì„¤ì •ë¨")

        page = context.new_page()

        # ë„¤íŠ¸ì›Œí¬ ìš”ì²­ ë¡œê¹…
        def on_request(request):
            req_data = {
                'timestamp': datetime.now().isoformat(),
                'url': request.url,
                'method': request.method,
                'resource_type': request.resource_type,
                'headers': dict(request.headers),
                'post_data': request.post_data[:500] if request.post_data else None
            }
            requests_log.append(req_data)

            # ì¤‘ìš” ìš”ì²­ë§Œ ì¶œë ¥
            if request.resource_type in ['document', 'xhr', 'fetch']:
                url_short = request.url[:80] + '...' if len(request.url) > 80 else request.url
                print(f"[REQ] {request.method} {request.resource_type}: {url_short}")

        def on_response(response):
            resp_data = {
                'timestamp': datetime.now().isoformat(),
                'url': response.url,
                'status': response.status,
                'headers': dict(response.headers),
            }
            responses_log.append(resp_data)

        page.on('request', on_request)
        page.on('response', on_response)

        # 1ë‹¨ê³„: ê²€ìƒ‰ í˜ì´ì§€ ì ‘ì†
        print("\n[1/4] ê²€ìƒ‰ í˜ì´ì§€ ì ‘ì†...")
        search_url = f"https://www.coupang.com/np/search?q={TARGET_PRODUCT['query']}"
        page.goto(search_url, wait_until='domcontentloaded', timeout=60000)
        page.wait_for_timeout(5000)

        # í˜ì´ì§€ ìƒíƒœ í™•ì¸
        current_url = page.url
        print(f"í˜„ì¬ URL: {current_url[:80]}...")

        # 2ë‹¨ê³„: ìƒí’ˆ ì°¾ê¸°
        print(f"\n[2/4] ìƒí’ˆ ì°¾ê¸°... (ID: {TARGET_PRODUCT['product_id']})")

        # ìƒí’ˆ ë§í¬ ì°¾ê¸° (ì—¬ëŸ¬ ì…€ë ‰í„° ì‹œë„)
        product_link = None
        selectors = [
            f"a[href*='products/{TARGET_PRODUCT['product_id']}']",
            f"a[data-product-id='{TARGET_PRODUCT['product_id']}']",
            f"li[data-product-id='{TARGET_PRODUCT['product_id']}'] a",
        ]

        for selector in selectors:
            product_link = page.query_selector(selector)
            if product_link:
                print(f"ë§¤ì¹­ ì…€ë ‰í„°: {selector}")
                break

        if not product_link:
            print("âŒ ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            # í˜ì´ì§€ ìŠ¤í¬ë¦°ìƒ·
            page.screenshot(path='click-tracker/search_page.png')
            print("ğŸ“¸ ìŠ¤í¬ë¦°ìƒ·: click-tracker/search_page.png")

            # í˜ì´ì§€ ë‚´ìš© ì¼ë¶€ ì¶œë ¥
            page_content = page.content()
            if 'Access Denied' in page_content:
                print("âš ï¸  Access Denied - Akamai ì°¨ë‹¨")
            elif 'challenge' in page_content.lower():
                print("âš ï¸  Challenge í˜ì´ì§€ ê°ì§€")

            browser.close()
            return

        # ìƒí’ˆ ì •ë³´ ì¶”ì¶œ
        product_url = product_link.get_attribute('href')
        print(f"âœ… ìƒí’ˆ ë°œê²¬: {product_url[:60]}...")

        # ì „ì²´ URL ìƒì„±
        if product_url.startswith('/'):
            full_product_url = f"https://www.coupang.com{product_url}"
        else:
            full_product_url = product_url

        # 3ë‹¨ê³„: ìƒí’ˆ í˜ì´ì§€ ì´ë™
        print("\n[3/4] ìƒí’ˆ í˜ì´ì§€ ì´ë™...")
        print("-" * 70)

        # í´ë¦­ ì „ ìš”ì²­ ìˆ˜ ê¸°ë¡
        requests_before_click = len(requests_log)

        # Referer ì„¤ì •í•˜ê³  ìƒí’ˆ í˜ì´ì§€ë¡œ ì´ë™
        search_referer = page.url
        page.set_extra_http_headers({'Referer': search_referer})

        # ìƒí’ˆ í˜ì´ì§€ë¡œ ì´ë™
        page.goto(full_product_url, wait_until='domcontentloaded', timeout=60000)
        page.wait_for_timeout(5000)  # ì¶”ê°€ ìš”ì²­ ëŒ€ê¸° (API í˜¸ì¶œ í¬í•¨)

        print("-" * 70)

        # 4ë‹¨ê³„: í´ë¦­ í›„ ìš”ì²­ ë¶„ì„
        print("\n[4/4] í´ë¦­ í›„ ìš”ì²­ ë¶„ì„...")

        requests_after_click = requests_log[requests_before_click:]

        # ìš”ì²­ ìœ í˜•ë³„ ë¶„ë¥˜
        request_types = {}
        domains = {}

        for req in requests_after_click:
            # ìœ í˜•ë³„
            rtype = req['resource_type']
            request_types[rtype] = request_types.get(rtype, 0) + 1

            # ë„ë©”ì¸ë³„
            from urllib.parse import urlparse
            domain = urlparse(req['url']).netloc
            domains[domain] = domains.get(domain, 0) + 1

        print(f"\nì´ ìš”ì²­ ìˆ˜: {len(requests_after_click)}")

        print("\n[ìš”ì²­ ìœ í˜•]")
        for rtype, count in sorted(request_types.items(), key=lambda x: -x[1]):
            print(f"  {rtype}: {count}")

        print("\n[ë„ë©”ì¸]")
        for domain, count in sorted(domains.items(), key=lambda x: -x[1])[:10]:
            print(f"  {domain}: {count}")

        # ì¤‘ìš” API ìš”ì²­ ì¶”ì¶œ
        print("\n[XHR/Fetch ìš”ì²­]")
        api_requests = [r for r in requests_after_click if r['resource_type'] in ['xhr', 'fetch']]
        for req in api_requests:
            url_short = req['url'][:100]
            print(f"  {req['method']} {url_short}")

        # ìŠ¤í¬ë¦°ìƒ·
        page.screenshot(path='click-tracker/product_page.png')
        print("\nğŸ“¸ ìŠ¤í¬ë¦°ìƒ·: click-tracker/product_page.png")

        browser.close()

    # ê²°ê³¼ ì €ì¥
    output_dir = Path(__file__).parent

    # ì „ì²´ ìš”ì²­ ë¡œê·¸
    with open(output_dir / 'requests_log.json', 'w', encoding='utf-8') as f:
        json.dump(requests_log, f, ensure_ascii=False, indent=2)

    # í´ë¦­ í›„ ìš”ì²­ë§Œ
    with open(output_dir / 'click_requests.json', 'w', encoding='utf-8') as f:
        json.dump(requests_after_click, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“ ë¡œê·¸ ì €ì¥:")
    print(f"   - click-tracker/requests_log.json (ì „ì²´: {len(requests_log)}ê°œ)")
    print(f"   - click-tracker/click_requests.json (í´ë¦­ í›„: {len(requests_after_click)}ê°œ)")

    # ìš”ì•½
    print("\n" + "=" * 70)
    print("ìš”ì•½")
    print("=" * 70)
    print(f"ê²€ìƒ‰ â†’ í´ë¦­ê¹Œì§€ ì´ ìš”ì²­: {len(requests_log)}")
    print(f"í´ë¦­ í›„ ìš”ì²­: {len(requests_after_click)}")
    print(f"API ìš”ì²­ (XHR/Fetch): {len(api_requests)}")

    return {
        'total_requests': len(requests_log),
        'click_requests': len(requests_after_click),
        'api_requests': len(api_requests),
        'requests_log': requests_log,
        'click_requests_log': requests_after_click
    }

if __name__ == '__main__':
    monitor_product_click()
